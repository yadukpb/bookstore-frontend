{"ast":null,"code":"\"use strict\";\n\n/*!\n * Copyright 2022 Google LLC. All Rights Reserved.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\nvar __createBinding = this && this.__createBinding || (Object.create ? function (o, m, k, k2) {\n  if (k2 === undefined) k2 = k;\n  var desc = Object.getOwnPropertyDescriptor(m, k);\n  if (!desc || (\"get\" in desc ? !m.__esModule : desc.writable || desc.configurable)) {\n    desc = {\n      enumerable: true,\n      get: function () {\n        return m[k];\n      }\n    };\n  }\n  Object.defineProperty(o, k2, desc);\n} : function (o, m, k, k2) {\n  if (k2 === undefined) k2 = k;\n  o[k2] = m[k];\n});\nvar __setModuleDefault = this && this.__setModuleDefault || (Object.create ? function (o, v) {\n  Object.defineProperty(o, \"default\", {\n    enumerable: true,\n    value: v\n  });\n} : function (o, v) {\n  o[\"default\"] = v;\n});\nvar __importStar = this && this.__importStar || function (mod) {\n  if (mod && mod.__esModule) return mod;\n  var result = {};\n  if (mod != null) for (var k in mod) if (k !== \"default\" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n  __setModuleDefault(result, mod);\n  return result;\n};\nvar __classPrivateFieldGet = this && this.__classPrivateFieldGet || function (receiver, state, kind, f) {\n  if (kind === \"a\" && !f) throw new TypeError(\"Private accessor was defined without a getter\");\n  if (typeof state === \"function\" ? receiver !== state || !f : !state.has(receiver)) throw new TypeError(\"Cannot read private member from an object whose class did not declare it\");\n  return kind === \"m\" ? f : kind === \"a\" ? f.call(receiver) : f ? f.value : state.get(receiver);\n};\nvar __importDefault = this && this.__importDefault || function (mod) {\n  return mod && mod.__esModule ? mod : {\n    \"default\": mod\n  };\n};\nvar _XMLMultiPartUploadHelper_instances, _XMLMultiPartUploadHelper_setGoogApiClientHeaders, _XMLMultiPartUploadHelper_handleErrorResponse;\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.TransferManager = exports.MultiPartUploadError = void 0;\nconst file_js_1 = require(\"./file.js\");\nconst p_limit_1 = __importDefault(require(\"p-limit\"));\nconst path = __importStar(require(\"path\"));\nconst fs_1 = require(\"fs\");\nconst crc32c_js_1 = require(\"./crc32c.js\");\nconst google_auth_library_1 = require(\"google-auth-library\");\nconst fast_xml_parser_1 = require(\"fast-xml-parser\");\nconst async_retry_1 = __importDefault(require(\"async-retry\"));\nconst crypto_1 = require(\"crypto\");\nconst util_js_1 = require(\"./nodejs-common/util.js\");\nconst util_js_2 = require(\"./util.js\");\n// eslint-disable-next-line @typescript-eslint/ban-ts-comment\n// @ts-ignore\nconst package_json_helper_cjs_1 = require(\"./package-json-helper.cjs\");\nconst packageJson = (0, package_json_helper_cjs_1.getPackageJSON)();\n/**\n * Default number of concurrently executing promises to use when calling uploadManyFiles.\n *\n */\nconst DEFAULT_PARALLEL_UPLOAD_LIMIT = 5;\n/**\n * Default number of concurrently executing promises to use when calling downloadManyFiles.\n *\n */\nconst DEFAULT_PARALLEL_DOWNLOAD_LIMIT = 5;\n/**\n * Default number of concurrently executing promises to use when calling downloadFileInChunks.\n *\n */\nconst DEFAULT_PARALLEL_CHUNKED_DOWNLOAD_LIMIT = 5;\n/**\n * The minimum size threshold in bytes at which to apply a chunked download strategy when calling downloadFileInChunks.\n *\n */\nconst DOWNLOAD_IN_CHUNKS_FILE_SIZE_THRESHOLD = 32 * 1024 * 1024;\n/**\n * The chunk size in bytes to use when calling downloadFileInChunks.\n *\n */\nconst DOWNLOAD_IN_CHUNKS_DEFAULT_CHUNK_SIZE = 32 * 1024 * 1024;\n/**\n * The chunk size in bytes to use when calling uploadFileInChunks.\n *\n */\nconst UPLOAD_IN_CHUNKS_DEFAULT_CHUNK_SIZE = 32 * 1024 * 1024;\n/**\n * Default number of concurrently executing promises to use when calling uploadFileInChunks.\n *\n */\nconst DEFAULT_PARALLEL_CHUNKED_UPLOAD_LIMIT = 5;\nconst EMPTY_REGEX = '(?:)';\n/**\n * The `gccl-gcs-cmd` value for the `X-Goog-API-Client` header.\n * Example: `gccl-gcs-cmd/tm.upload_many`\n *\n * @see {@link GCCL_GCS_CMD}.\n * @see {@link GCCL_GCS_CMD_KEY}.\n */\nconst GCCL_GCS_CMD_FEATURE = {\n  UPLOAD_MANY: 'tm.upload_many',\n  DOWNLOAD_MANY: 'tm.download_many',\n  UPLOAD_SHARDED: 'tm.upload_sharded',\n  DOWNLOAD_SHARDED: 'tm.download_sharded'\n};\nconst defaultMultiPartGenerator = (bucket, fileName, uploadId, partsMap) => {\n  return new XMLMultiPartUploadHelper(bucket, fileName, uploadId, partsMap);\n};\nclass MultiPartUploadError extends Error {\n  constructor(message, uploadId, partsMap) {\n    super(message);\n    this.uploadId = uploadId;\n    this.partsMap = partsMap;\n  }\n}\nexports.MultiPartUploadError = MultiPartUploadError;\n/**\n * Class representing an implementation of MPU in the XML API. This class is not meant for public usage.\n *\n * @private\n *\n */\nclass XMLMultiPartUploadHelper {\n  constructor(bucket, fileName, uploadId, partsMap) {\n    _XMLMultiPartUploadHelper_instances.add(this);\n    this.authClient = bucket.storage.authClient || new google_auth_library_1.GoogleAuth();\n    this.uploadId = uploadId || '';\n    this.bucket = bucket;\n    this.fileName = fileName;\n    this.baseUrl = `https://${bucket.name}.${new URL(this.bucket.storage.apiEndpoint).hostname}/${fileName}`;\n    this.xmlBuilder = new fast_xml_parser_1.XMLBuilder({\n      arrayNodeName: 'Part'\n    });\n    this.xmlParser = new fast_xml_parser_1.XMLParser();\n    this.partsMap = partsMap || new Map();\n    this.retryOptions = {\n      retries: this.bucket.storage.retryOptions.maxRetries,\n      factor: this.bucket.storage.retryOptions.retryDelayMultiplier,\n      maxTimeout: this.bucket.storage.retryOptions.maxRetryDelay * 1000,\n      maxRetryTime: this.bucket.storage.retryOptions.totalTimeout * 1000\n    };\n  }\n  /**\n   * Initiates a multipart upload (MPU) to the XML API and stores the resultant upload id.\n   *\n   * @returns {Promise<void>}\n   */\n  async initiateUpload() {\n    let headers = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n    const url = `${this.baseUrl}?uploads`;\n    return (0, async_retry_1.default)(async bail => {\n      try {\n        const res = await this.authClient.request({\n          headers: __classPrivateFieldGet(this, _XMLMultiPartUploadHelper_instances, \"m\", _XMLMultiPartUploadHelper_setGoogApiClientHeaders).call(this, headers),\n          method: 'POST',\n          url\n        });\n        if (res.data && res.data.error) {\n          throw res.data.error;\n        }\n        const parsedXML = this.xmlParser.parse(res.data);\n        this.uploadId = parsedXML.InitiateMultipartUploadResult.UploadId;\n      } catch (e) {\n        __classPrivateFieldGet(this, _XMLMultiPartUploadHelper_instances, \"m\", _XMLMultiPartUploadHelper_handleErrorResponse).call(this, e, bail);\n      }\n    }, this.retryOptions);\n  }\n  /**\n   * Uploads the provided chunk of data to the XML API using the previously created upload id.\n   *\n   * @param {number} partNumber the sequence number of this chunk.\n   * @param {Buffer} chunk the chunk of data to be uploaded.\n   * @param {string | false} validation whether or not to include the md5 hash in the headers to cause the server\n   * to validate the chunk was not corrupted.\n   * @returns {Promise<void>}\n   */\n  async uploadPart(partNumber, chunk, validation) {\n    const url = `${this.baseUrl}?partNumber=${partNumber}&uploadId=${this.uploadId}`;\n    let headers = __classPrivateFieldGet(this, _XMLMultiPartUploadHelper_instances, \"m\", _XMLMultiPartUploadHelper_setGoogApiClientHeaders).call(this);\n    if (validation === 'md5') {\n      const hash = (0, crypto_1.createHash)('md5').update(chunk).digest('base64');\n      headers = {\n        'Content-MD5': hash\n      };\n    }\n    return (0, async_retry_1.default)(async bail => {\n      try {\n        const res = await this.authClient.request({\n          url,\n          method: 'PUT',\n          body: chunk,\n          headers\n        });\n        if (res.data && res.data.error) {\n          throw res.data.error;\n        }\n        this.partsMap.set(partNumber, res.headers['etag']);\n      } catch (e) {\n        __classPrivateFieldGet(this, _XMLMultiPartUploadHelper_instances, \"m\", _XMLMultiPartUploadHelper_handleErrorResponse).call(this, e, bail);\n      }\n    }, this.retryOptions);\n  }\n  /**\n   * Sends the final request of the MPU to tell GCS the upload is now complete.\n   *\n   * @returns {Promise<void>}\n   */\n  async completeUpload() {\n    const url = `${this.baseUrl}?uploadId=${this.uploadId}`;\n    const sortedMap = new Map([...this.partsMap.entries()].sort((a, b) => a[0] - b[0]));\n    const parts = [];\n    for (const entry of sortedMap.entries()) {\n      parts.push({\n        PartNumber: entry[0],\n        ETag: entry[1]\n      });\n    }\n    const body = `<CompleteMultipartUpload>${this.xmlBuilder.build(parts)}</CompleteMultipartUpload>`;\n    return (0, async_retry_1.default)(async bail => {\n      try {\n        const res = await this.authClient.request({\n          headers: __classPrivateFieldGet(this, _XMLMultiPartUploadHelper_instances, \"m\", _XMLMultiPartUploadHelper_setGoogApiClientHeaders).call(this),\n          url,\n          method: 'POST',\n          body\n        });\n        if (res.data && res.data.error) {\n          throw res.data.error;\n        }\n        return res;\n      } catch (e) {\n        __classPrivateFieldGet(this, _XMLMultiPartUploadHelper_instances, \"m\", _XMLMultiPartUploadHelper_handleErrorResponse).call(this, e, bail);\n        return;\n      }\n    }, this.retryOptions);\n  }\n  /**\n   * Aborts an multipart upload that is in progress. Once aborted, any parts in the process of being uploaded fail,\n   * and future requests using the upload ID fail.\n   *\n   * @returns {Promise<void>}\n   */\n  async abortUpload() {\n    const url = `${this.baseUrl}?uploadId=${this.uploadId}`;\n    return (0, async_retry_1.default)(async bail => {\n      try {\n        const res = await this.authClient.request({\n          url,\n          method: 'DELETE'\n        });\n        if (res.data && res.data.error) {\n          throw res.data.error;\n        }\n      } catch (e) {\n        __classPrivateFieldGet(this, _XMLMultiPartUploadHelper_instances, \"m\", _XMLMultiPartUploadHelper_handleErrorResponse).call(this, e, bail);\n        return;\n      }\n    }, this.retryOptions);\n  }\n}\n_XMLMultiPartUploadHelper_instances = new WeakSet(), _XMLMultiPartUploadHelper_setGoogApiClientHeaders = function _XMLMultiPartUploadHelper_setGoogApiClientHeaders() {\n  let headers = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n  let headerFound = false;\n  let userAgentFound = false;\n  for (const [key, value] of Object.entries(headers)) {\n    if (key.toLocaleLowerCase().trim() === 'x-goog-api-client') {\n      headerFound = true;\n      // Prepend command feature to value, if not already there\n      if (!value.includes(GCCL_GCS_CMD_FEATURE.UPLOAD_SHARDED)) {\n        headers[key] = `${value} gccl-gcs-cmd/${GCCL_GCS_CMD_FEATURE.UPLOAD_SHARDED}`;\n      }\n    } else if (key.toLocaleLowerCase().trim() === 'user-agent') {\n      userAgentFound = true;\n    }\n  }\n  // If the header isn't present, add it\n  if (!headerFound) {\n    headers['x-goog-api-client'] = `${(0, util_js_2.getRuntimeTrackingString)()} gccl/${packageJson.version} gccl-gcs-cmd/${GCCL_GCS_CMD_FEATURE.UPLOAD_SHARDED}`;\n  }\n  // If the User-Agent isn't present, add it\n  if (!userAgentFound) {\n    headers['User-Agent'] = (0, util_js_2.getUserAgentString)();\n  }\n  return headers;\n}, _XMLMultiPartUploadHelper_handleErrorResponse = function _XMLMultiPartUploadHelper_handleErrorResponse(err, bail) {\n  if (this.bucket.storage.retryOptions.autoRetry && this.bucket.storage.retryOptions.retryableErrorFn(err)) {\n    throw err;\n  } else {\n    bail(err);\n  }\n};\n/**\n * Create a TransferManager object to perform parallel transfer operations on a Cloud Storage bucket.\n *\n * @class\n * @hideconstructor\n *\n * @param {Bucket} bucket A {@link Bucket} instance\n *\n */\nclass TransferManager {\n  constructor(bucket) {\n    this.bucket = bucket;\n  }\n  /**\n   * @typedef {object} UploadManyFilesOptions\n   * @property {number} [concurrencyLimit] The number of concurrently executing promises\n   * to use when uploading the files.\n   * @property {Function} [customDestinationBuilder] A fuction that will take the current path of a local file\n   * and return a string representing a custom path to be used to upload the file to GCS.\n   * @property {boolean} [skipIfExists] Do not upload the file if it already exists in\n   * the bucket. This will set the precondition ifGenerationMatch = 0.\n   * @property {string} [prefix] A prefix to append to all of the uploaded files.\n   * @property {object} [passthroughOptions] {@link UploadOptions} Options to be passed through\n   * to each individual upload operation.\n   *\n   */\n  /**\n   * Upload multiple files in parallel to the bucket. This is a convenience method\n   * that utilizes {@link Bucket#upload} to perform the upload.\n   *\n   * @param {array | string} [filePathsOrDirectory] An array of fully qualified paths to the files or a directory name.\n   * If a directory name is provided, the directory will be recursively walked and all files will be added to the upload list.\n   * to be uploaded to the bucket\n   * @param {UploadManyFilesOptions} [options] Configuration options.\n   * @returns {Promise<UploadResponse[]>}\n   *\n   * @example\n   * ```\n   * const {Storage} = require('@google-cloud/storage');\n   * const storage = new Storage();\n   * const bucket = storage.bucket('my-bucket');\n   * const transferManager = new TransferManager(bucket);\n   *\n   * //-\n   * // Upload multiple files in parallel.\n   * //-\n   * const response = await transferManager.uploadManyFiles(['/local/path/file1.txt, 'local/path/file2.txt']);\n   * // Your bucket now contains:\n   * // - \"local/path/file1.txt\" (with the contents of '/local/path/file1.txt')\n   * // - \"local/path/file2.txt\" (with the contents of '/local/path/file2.txt')\n   * const response = await transferManager.uploadManyFiles('/local/directory');\n   * // Your bucket will now contain all files contained in '/local/directory' maintaining the subdirectory structure.\n   * ```\n   *\n   */\n  async uploadManyFiles(filePathsOrDirectory) {\n    let options = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n    var _a;\n    if (options.skipIfExists && ((_a = options.passthroughOptions) === null || _a === void 0 ? void 0 : _a.preconditionOpts)) {\n      options.passthroughOptions.preconditionOpts.ifGenerationMatch = 0;\n    } else if (options.skipIfExists && options.passthroughOptions === undefined) {\n      options.passthroughOptions = {\n        preconditionOpts: {\n          ifGenerationMatch: 0\n        }\n      };\n    }\n    const limit = (0, p_limit_1.default)(options.concurrencyLimit || DEFAULT_PARALLEL_UPLOAD_LIMIT);\n    const promises = [];\n    let allPaths = [];\n    if (!Array.isArray(filePathsOrDirectory)) {\n      for await (const curPath of this.getPathsFromDirectory(filePathsOrDirectory)) {\n        allPaths.push(curPath);\n      }\n    } else {\n      allPaths = filePathsOrDirectory;\n    }\n    for (const filePath of allPaths) {\n      const stat = await fs_1.promises.lstat(filePath);\n      if (stat.isDirectory()) {\n        continue;\n      }\n      const passThroughOptionsCopy = {\n        ...options.passthroughOptions,\n        [util_js_1.GCCL_GCS_CMD_KEY]: GCCL_GCS_CMD_FEATURE.UPLOAD_MANY\n      };\n      passThroughOptionsCopy.destination = options.customDestinationBuilder ? options.customDestinationBuilder(filePath, options) : filePath.split(path.sep).join(path.posix.sep);\n      if (options.prefix) {\n        passThroughOptionsCopy.destination = path.posix.join(...options.prefix.split(path.sep), passThroughOptionsCopy.destination);\n      }\n      promises.push(limit(() => this.bucket.upload(filePath, passThroughOptionsCopy)));\n    }\n    return Promise.all(promises);\n  }\n  /**\n   * @typedef {object} DownloadManyFilesOptions\n   * @property {number} [concurrencyLimit] The number of concurrently executing promises\n   * to use when downloading the files.\n   * @property {string} [prefix] A prefix to append to all of the downloaded files.\n   * @property {string} [stripPrefix] A prefix to remove from all of the downloaded files.\n   * @property {object} [passthroughOptions] {@link DownloadOptions} Options to be passed through\n   * to each individual download operation.\n   * @property {boolean} [skipIfExists] Do not download the file if it already exists in\n   * the destination.\n   *\n   */\n  /**\n   * Download multiple files in parallel to the local filesystem. This is a convenience method\n   * that utilizes {@link File#download} to perform the download.\n   *\n   * @param {array | string} [filesOrFolder] An array of file name strings or file objects to be downloaded. If\n   * a string is provided this will be treated as a GCS prefix and all files with that prefix will be downloaded.\n   * @param {DownloadManyFilesOptions} [options] Configuration options. Setting options.prefix or options.stripPrefix\n   * or options.passthroughOptions.destination will cause the downloaded files to be written to the file system\n   * instead of being returned as a buffer.\n   * @returns {Promise<DownloadResponse[]>}\n   *\n   * @example\n   * ```\n   * const {Storage} = require('@google-cloud/storage');\n   * const storage = new Storage();\n   * const bucket = storage.bucket('my-bucket');\n   * const transferManager = new TransferManager(bucket);\n   *\n   * //-\n   * // Download multiple files in parallel.\n   * //-\n   * const response = await transferManager.downloadManyFiles(['file1.txt', 'file2.txt']);\n   * // The following files have been downloaded:\n   * // - \"file1.txt\" (with the contents from my-bucket.file1.txt)\n   * // - \"file2.txt\" (with the contents from my-bucket.file2.txt)\n   * const response = await transferManager.downloadManyFiles([bucket.File('file1.txt'), bucket.File('file2.txt')]);\n   * // The following files have been downloaded:\n   * // - \"file1.txt\" (with the contents from my-bucket.file1.txt)\n   * // - \"file2.txt\" (with the contents from my-bucket.file2.txt)\n   * const response = await transferManager.downloadManyFiles('test-folder');\n   * // All files with GCS prefix of 'test-folder' have been downloaded.\n   * ```\n   *\n   */\n  async downloadManyFiles(filesOrFolder) {\n    let options = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n    const limit = (0, p_limit_1.default)(options.concurrencyLimit || DEFAULT_PARALLEL_DOWNLOAD_LIMIT);\n    const promises = [];\n    let files = [];\n    if (!Array.isArray(filesOrFolder)) {\n      const directoryFiles = await this.bucket.getFiles({\n        prefix: filesOrFolder\n      });\n      files = directoryFiles[0];\n    } else {\n      files = filesOrFolder.map(curFile => {\n        if (typeof curFile === 'string') {\n          return this.bucket.file(curFile);\n        }\n        return curFile;\n      });\n    }\n    const stripRegexString = options.stripPrefix ? `^${options.stripPrefix}` : EMPTY_REGEX;\n    const regex = new RegExp(stripRegexString, 'g');\n    for (const file of files) {\n      const passThroughOptionsCopy = {\n        ...options.passthroughOptions,\n        [util_js_1.GCCL_GCS_CMD_KEY]: GCCL_GCS_CMD_FEATURE.DOWNLOAD_MANY\n      };\n      if (options.prefix || passThroughOptionsCopy.destination) {\n        passThroughOptionsCopy.destination = path.join(options.prefix || '', passThroughOptionsCopy.destination || '', file.name);\n      }\n      if (options.stripPrefix) {\n        passThroughOptionsCopy.destination = file.name.replace(regex, '');\n      }\n      if (options.skipIfExists && (0, fs_1.existsSync)(passThroughOptionsCopy.destination || '')) {\n        continue;\n      }\n      promises.push(limit(async () => {\n        const destination = passThroughOptionsCopy.destination;\n        if (destination && destination.endsWith(path.sep)) {\n          await fs_1.promises.mkdir(destination, {\n            recursive: true\n          });\n          return Promise.resolve([Buffer.alloc(0)]);\n        }\n        return file.download(passThroughOptionsCopy);\n      }));\n    }\n    return Promise.all(promises);\n  }\n  /**\n   * @typedef {object} DownloadFileInChunksOptions\n   * @property {number} [concurrencyLimit] The number of concurrently executing promises\n   * to use when downloading the file.\n   * @property {number} [chunkSizeBytes] The size in bytes of each chunk to be downloaded.\n   * @property {string | boolean} [validation] Whether or not to perform a CRC32C validation check when download is complete.\n   * @property {boolean} [noReturnData] Whether or not to return the downloaded data. A `true` value here would be useful for files with a size that will not fit into memory.\n   *\n   */\n  /**\n   * Download a large file in chunks utilizing parallel download operations. This is a convenience method\n   * that utilizes {@link File#download} to perform the download.\n   *\n   * @param {File | string} fileOrName {@link File} to download.\n   * @param {DownloadFileInChunksOptions} [options] Configuration options.\n   * @returns {Promise<void | DownloadResponse>}\n   *\n   * @example\n   * ```\n   * const {Storage} = require('@google-cloud/storage');\n   * const storage = new Storage();\n   * const bucket = storage.bucket('my-bucket');\n   * const transferManager = new TransferManager(bucket);\n   *\n   * //-\n   * // Download a large file in chunks utilizing parallel operations.\n   * //-\n   * const response = await transferManager.downloadFileInChunks(bucket.file('large-file.txt');\n   * // Your local directory now contains:\n   * // - \"large-file.txt\" (with the contents from my-bucket.large-file.txt)\n   * ```\n   *\n   */\n  async downloadFileInChunks(fileOrName) {\n    let options = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n    let chunkSize = options.chunkSizeBytes || DOWNLOAD_IN_CHUNKS_DEFAULT_CHUNK_SIZE;\n    let limit = (0, p_limit_1.default)(options.concurrencyLimit || DEFAULT_PARALLEL_CHUNKED_DOWNLOAD_LIMIT);\n    const noReturnData = Boolean(options.noReturnData);\n    const promises = [];\n    const file = typeof fileOrName === 'string' ? this.bucket.file(fileOrName) : fileOrName;\n    const fileInfo = await file.get();\n    const size = parseInt(fileInfo[0].metadata.size.toString());\n    // If the file size does not meet the threshold download it as a single chunk.\n    if (size < DOWNLOAD_IN_CHUNKS_FILE_SIZE_THRESHOLD) {\n      limit = (0, p_limit_1.default)(1);\n      chunkSize = size;\n    }\n    let start = 0;\n    const filePath = options.destination || path.basename(file.name);\n    const fileToWrite = await fs_1.promises.open(filePath, 'w');\n    while (start < size) {\n      const chunkStart = start;\n      let chunkEnd = start + chunkSize - 1;\n      chunkEnd = chunkEnd > size ? size : chunkEnd;\n      promises.push(limit(async () => {\n        const resp = await file.download({\n          start: chunkStart,\n          end: chunkEnd,\n          [util_js_1.GCCL_GCS_CMD_KEY]: GCCL_GCS_CMD_FEATURE.DOWNLOAD_SHARDED\n        });\n        const result = await fileToWrite.write(resp[0], 0, resp[0].length, chunkStart);\n        if (noReturnData) return;\n        return result.buffer;\n      }));\n      start += chunkSize;\n    }\n    let chunks;\n    try {\n      chunks = await Promise.all(promises);\n    } finally {\n      await fileToWrite.close();\n    }\n    if (options.validation === 'crc32c' && fileInfo[0].metadata.crc32c) {\n      const downloadedCrc32C = await crc32c_js_1.CRC32C.fromFile(filePath);\n      if (!downloadedCrc32C.validate(fileInfo[0].metadata.crc32c)) {\n        const mismatchError = new file_js_1.RequestError(file_js_1.FileExceptionMessages.DOWNLOAD_MISMATCH);\n        mismatchError.code = 'CONTENT_DOWNLOAD_MISMATCH';\n        throw mismatchError;\n      }\n    }\n    if (noReturnData) return;\n    return [Buffer.concat(chunks, size)];\n  }\n  /**\n   * @typedef {object} UploadFileInChunksOptions\n   * @property {number} [concurrencyLimit] The number of concurrently executing promises\n   * to use when uploading the file.\n   * @property {number} [chunkSizeBytes] The size in bytes of each chunk to be uploaded.\n   * @property {string} [uploadName] Name of the file when saving to GCS. If ommitted the name is taken from the file path.\n   * @property {number} [maxQueueSize] The number of chunks to be uploaded to hold in memory concurrently. If not specified\n   * defaults to the specified concurrency limit.\n   * @property {string} [uploadId] If specified attempts to resume a previous upload.\n   * @property {Map} [partsMap] If specified alongside uploadId, attempts to resume a previous upload from the last chunk\n   * specified in partsMap\n   * @property {object} [headers] headers to be sent when initiating the multipart upload.\n   * See {@link https://cloud.google.com/storage/docs/xml-api/post-object-multipart#request_headers| Request Headers: Initiate a Multipart Upload}\n   * @property {boolean} [autoAbortFailure] boolean to indicate if an in progress upload session will be automatically aborted upon failure. If not set,\n   * failures will be automatically aborted.\n   *\n   */\n  /**\n   * Upload a large file in chunks utilizing parallel upload opertions. If the upload fails, an uploadId and\n   * map containing all the successfully uploaded parts will be returned to the caller. These arguments can be used to\n   * resume the upload.\n   *\n   * @param {string} [filePath] The path of the file to be uploaded\n   * @param {UploadFileInChunksOptions} [options] Configuration options.\n   * @param {MultiPartHelperGenerator} [generator] A function that will return a type that implements the MPU interface. Most users will not need to use this.\n   * @returns {Promise<void>} If successful a promise resolving to void, otherwise a error containing the message, uploadid, and parts map.\n   *\n   * @example\n   * ```\n   * const {Storage} = require('@google-cloud/storage');\n   * const storage = new Storage();\n   * const bucket = storage.bucket('my-bucket');\n   * const transferManager = new TransferManager(bucket);\n   *\n   * //-\n   * // Upload a large file in chunks utilizing parallel operations.\n   * //-\n   * const response = await transferManager.uploadFileInChunks('large-file.txt');\n   * // Your bucket now contains:\n   * // - \"large-file.txt\"\n   * ```\n   *\n   *\n   */\n  async uploadFileInChunks(filePath) {\n    let options = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n    let generator = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : defaultMultiPartGenerator;\n    const chunkSize = options.chunkSizeBytes || UPLOAD_IN_CHUNKS_DEFAULT_CHUNK_SIZE;\n    const limit = (0, p_limit_1.default)(options.concurrencyLimit || DEFAULT_PARALLEL_CHUNKED_UPLOAD_LIMIT);\n    const maxQueueSize = options.maxQueueSize || options.concurrencyLimit || DEFAULT_PARALLEL_CHUNKED_UPLOAD_LIMIT;\n    const fileName = options.uploadName || path.basename(filePath);\n    const mpuHelper = generator(this.bucket, fileName, options.uploadId, options.partsMap);\n    let partNumber = 1;\n    let promises = [];\n    try {\n      if (options.uploadId === undefined) {\n        await mpuHelper.initiateUpload(options.headers);\n      }\n      const startOrResumptionByte = mpuHelper.partsMap.size * chunkSize;\n      const readStream = (0, fs_1.createReadStream)(filePath, {\n        highWaterMark: chunkSize,\n        start: startOrResumptionByte\n      });\n      // p-limit only limits the number of running promises. We do not want to hold an entire\n      // large file in memory at once so promises acts a queue that will hold only maxQueueSize in memory.\n      for await (const curChunk of readStream) {\n        if (promises.length >= maxQueueSize) {\n          await Promise.all(promises);\n          promises = [];\n        }\n        promises.push(limit(() => mpuHelper.uploadPart(partNumber++, curChunk, options.validation)));\n      }\n      await Promise.all(promises);\n      return await mpuHelper.completeUpload();\n    } catch (e) {\n      if ((options.autoAbortFailure === undefined || options.autoAbortFailure) && mpuHelper.uploadId) {\n        try {\n          await mpuHelper.abortUpload();\n          return;\n        } catch (e) {\n          throw new MultiPartUploadError(e.message, mpuHelper.uploadId, mpuHelper.partsMap);\n        }\n      }\n      throw new MultiPartUploadError(e.message, mpuHelper.uploadId, mpuHelper.partsMap);\n    }\n  }\n  async *getPathsFromDirectory(directory) {\n    const filesAndSubdirectories = await fs_1.promises.readdir(directory, {\n      withFileTypes: true\n    });\n    for (const curFileOrDirectory of filesAndSubdirectories) {\n      const fullPath = path.join(directory, curFileOrDirectory.name);\n      curFileOrDirectory.isDirectory() ? yield* this.getPathsFromDirectory(fullPath) : yield fullPath;\n    }\n  }\n}\nexports.TransferManager = TransferManager;","map":{"version":3,"names":["__createBinding","Object","create","o","m","k","k2","undefined","desc","getOwnPropertyDescriptor","__esModule","writable","configurable","enumerable","get","defineProperty","__setModuleDefault","v","value","__importStar","mod","result","prototype","hasOwnProperty","call","__classPrivateFieldGet","receiver","state","kind","f","TypeError","has","__importDefault","_XMLMultiPartUploadHelper_instances","_XMLMultiPartUploadHelper_setGoogApiClientHeaders","_XMLMultiPartUploadHelper_handleErrorResponse","exports","TransferManager","MultiPartUploadError","file_js_1","require","p_limit_1","path","fs_1","crc32c_js_1","google_auth_library_1","fast_xml_parser_1","async_retry_1","crypto_1","util_js_1","util_js_2","package_json_helper_cjs_1","packageJson","getPackageJSON","DEFAULT_PARALLEL_UPLOAD_LIMIT","DEFAULT_PARALLEL_DOWNLOAD_LIMIT","DEFAULT_PARALLEL_CHUNKED_DOWNLOAD_LIMIT","DOWNLOAD_IN_CHUNKS_FILE_SIZE_THRESHOLD","DOWNLOAD_IN_CHUNKS_DEFAULT_CHUNK_SIZE","UPLOAD_IN_CHUNKS_DEFAULT_CHUNK_SIZE","DEFAULT_PARALLEL_CHUNKED_UPLOAD_LIMIT","EMPTY_REGEX","GCCL_GCS_CMD_FEATURE","UPLOAD_MANY","DOWNLOAD_MANY","UPLOAD_SHARDED","DOWNLOAD_SHARDED","defaultMultiPartGenerator","bucket","fileName","uploadId","partsMap","XMLMultiPartUploadHelper","Error","constructor","message","add","authClient","storage","GoogleAuth","baseUrl","name","URL","apiEndpoint","hostname","xmlBuilder","XMLBuilder","arrayNodeName","xmlParser","XMLParser","Map","retryOptions","retries","maxRetries","factor","retryDelayMultiplier","maxTimeout","maxRetryDelay","maxRetryTime","totalTimeout","initiateUpload","headers","url","default","bail","res","request","method","data","error","parsedXML","parse","InitiateMultipartUploadResult","UploadId","e","uploadPart","partNumber","chunk","validation","hash","createHash","update","digest","body","set","completeUpload","sortedMap","entries","sort","a","b","parts","entry","push","PartNumber","ETag","build","abortUpload","WeakSet","headerFound","userAgentFound","key","toLocaleLowerCase","trim","includes","getRuntimeTrackingString","version","getUserAgentString","err","autoRetry","retryableErrorFn","uploadManyFiles","filePathsOrDirectory","options","_a","skipIfExists","passthroughOptions","preconditionOpts","ifGenerationMatch","limit","concurrencyLimit","promises","allPaths","Array","isArray","curPath","getPathsFromDirectory","filePath","stat","lstat","isDirectory","passThroughOptionsCopy","GCCL_GCS_CMD_KEY","destination","customDestinationBuilder","split","sep","join","posix","prefix","upload","Promise","all","downloadManyFiles","filesOrFolder","files","directoryFiles","getFiles","map","curFile","file","stripRegexString","stripPrefix","regex","RegExp","replace","existsSync","endsWith","mkdir","recursive","resolve","Buffer","alloc","download","downloadFileInChunks","fileOrName","chunkSize","chunkSizeBytes","noReturnData","Boolean","fileInfo","size","parseInt","metadata","toString","start","basename","fileToWrite","open","chunkStart","chunkEnd","resp","end","write","length","buffer","chunks","close","crc32c","downloadedCrc32C","CRC32C","fromFile","validate","mismatchError","RequestError","FileExceptionMessages","DOWNLOAD_MISMATCH","code","concat","uploadFileInChunks","generator","maxQueueSize","uploadName","mpuHelper","startOrResumptionByte","readStream","createReadStream","highWaterMark","curChunk","autoAbortFailure","directory","filesAndSubdirectories","readdir","withFileTypes","curFileOrDirectory","fullPath"],"sources":["/home/yadu/Music/Gifty/node_modules/@google-cloud/storage/build/cjs/src/transfer-manager.js"],"sourcesContent":["\"use strict\";\n/*!\n * Copyright 2022 Google LLC. All Rights Reserved.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    var desc = Object.getOwnPropertyDescriptor(m, k);\n    if (!desc || (\"get\" in desc ? !m.__esModule : desc.writable || desc.configurable)) {\n      desc = { enumerable: true, get: function() { return m[k]; } };\n    }\n    Object.defineProperty(o, k2, desc);\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nvar __classPrivateFieldGet = (this && this.__classPrivateFieldGet) || function (receiver, state, kind, f) {\n    if (kind === \"a\" && !f) throw new TypeError(\"Private accessor was defined without a getter\");\n    if (typeof state === \"function\" ? receiver !== state || !f : !state.has(receiver)) throw new TypeError(\"Cannot read private member from an object whose class did not declare it\");\n    return kind === \"m\" ? f : kind === \"a\" ? f.call(receiver) : f ? f.value : state.get(receiver);\n};\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nvar _XMLMultiPartUploadHelper_instances, _XMLMultiPartUploadHelper_setGoogApiClientHeaders, _XMLMultiPartUploadHelper_handleErrorResponse;\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.TransferManager = exports.MultiPartUploadError = void 0;\nconst file_js_1 = require(\"./file.js\");\nconst p_limit_1 = __importDefault(require(\"p-limit\"));\nconst path = __importStar(require(\"path\"));\nconst fs_1 = require(\"fs\");\nconst crc32c_js_1 = require(\"./crc32c.js\");\nconst google_auth_library_1 = require(\"google-auth-library\");\nconst fast_xml_parser_1 = require(\"fast-xml-parser\");\nconst async_retry_1 = __importDefault(require(\"async-retry\"));\nconst crypto_1 = require(\"crypto\");\nconst util_js_1 = require(\"./nodejs-common/util.js\");\nconst util_js_2 = require(\"./util.js\");\n// eslint-disable-next-line @typescript-eslint/ban-ts-comment\n// @ts-ignore\nconst package_json_helper_cjs_1 = require(\"./package-json-helper.cjs\");\nconst packageJson = (0, package_json_helper_cjs_1.getPackageJSON)();\n/**\n * Default number of concurrently executing promises to use when calling uploadManyFiles.\n *\n */\nconst DEFAULT_PARALLEL_UPLOAD_LIMIT = 5;\n/**\n * Default number of concurrently executing promises to use when calling downloadManyFiles.\n *\n */\nconst DEFAULT_PARALLEL_DOWNLOAD_LIMIT = 5;\n/**\n * Default number of concurrently executing promises to use when calling downloadFileInChunks.\n *\n */\nconst DEFAULT_PARALLEL_CHUNKED_DOWNLOAD_LIMIT = 5;\n/**\n * The minimum size threshold in bytes at which to apply a chunked download strategy when calling downloadFileInChunks.\n *\n */\nconst DOWNLOAD_IN_CHUNKS_FILE_SIZE_THRESHOLD = 32 * 1024 * 1024;\n/**\n * The chunk size in bytes to use when calling downloadFileInChunks.\n *\n */\nconst DOWNLOAD_IN_CHUNKS_DEFAULT_CHUNK_SIZE = 32 * 1024 * 1024;\n/**\n * The chunk size in bytes to use when calling uploadFileInChunks.\n *\n */\nconst UPLOAD_IN_CHUNKS_DEFAULT_CHUNK_SIZE = 32 * 1024 * 1024;\n/**\n * Default number of concurrently executing promises to use when calling uploadFileInChunks.\n *\n */\nconst DEFAULT_PARALLEL_CHUNKED_UPLOAD_LIMIT = 5;\nconst EMPTY_REGEX = '(?:)';\n/**\n * The `gccl-gcs-cmd` value for the `X-Goog-API-Client` header.\n * Example: `gccl-gcs-cmd/tm.upload_many`\n *\n * @see {@link GCCL_GCS_CMD}.\n * @see {@link GCCL_GCS_CMD_KEY}.\n */\nconst GCCL_GCS_CMD_FEATURE = {\n    UPLOAD_MANY: 'tm.upload_many',\n    DOWNLOAD_MANY: 'tm.download_many',\n    UPLOAD_SHARDED: 'tm.upload_sharded',\n    DOWNLOAD_SHARDED: 'tm.download_sharded',\n};\nconst defaultMultiPartGenerator = (bucket, fileName, uploadId, partsMap) => {\n    return new XMLMultiPartUploadHelper(bucket, fileName, uploadId, partsMap);\n};\nclass MultiPartUploadError extends Error {\n    constructor(message, uploadId, partsMap) {\n        super(message);\n        this.uploadId = uploadId;\n        this.partsMap = partsMap;\n    }\n}\nexports.MultiPartUploadError = MultiPartUploadError;\n/**\n * Class representing an implementation of MPU in the XML API. This class is not meant for public usage.\n *\n * @private\n *\n */\nclass XMLMultiPartUploadHelper {\n    constructor(bucket, fileName, uploadId, partsMap) {\n        _XMLMultiPartUploadHelper_instances.add(this);\n        this.authClient = bucket.storage.authClient || new google_auth_library_1.GoogleAuth();\n        this.uploadId = uploadId || '';\n        this.bucket = bucket;\n        this.fileName = fileName;\n        this.baseUrl = `https://${bucket.name}.${new URL(this.bucket.storage.apiEndpoint).hostname}/${fileName}`;\n        this.xmlBuilder = new fast_xml_parser_1.XMLBuilder({ arrayNodeName: 'Part' });\n        this.xmlParser = new fast_xml_parser_1.XMLParser();\n        this.partsMap = partsMap || new Map();\n        this.retryOptions = {\n            retries: this.bucket.storage.retryOptions.maxRetries,\n            factor: this.bucket.storage.retryOptions.retryDelayMultiplier,\n            maxTimeout: this.bucket.storage.retryOptions.maxRetryDelay * 1000,\n            maxRetryTime: this.bucket.storage.retryOptions.totalTimeout * 1000,\n        };\n    }\n    /**\n     * Initiates a multipart upload (MPU) to the XML API and stores the resultant upload id.\n     *\n     * @returns {Promise<void>}\n     */\n    async initiateUpload(headers = {}) {\n        const url = `${this.baseUrl}?uploads`;\n        return (0, async_retry_1.default)(async (bail) => {\n            try {\n                const res = await this.authClient.request({\n                    headers: __classPrivateFieldGet(this, _XMLMultiPartUploadHelper_instances, \"m\", _XMLMultiPartUploadHelper_setGoogApiClientHeaders).call(this, headers),\n                    method: 'POST',\n                    url,\n                });\n                if (res.data && res.data.error) {\n                    throw res.data.error;\n                }\n                const parsedXML = this.xmlParser.parse(res.data);\n                this.uploadId = parsedXML.InitiateMultipartUploadResult.UploadId;\n            }\n            catch (e) {\n                __classPrivateFieldGet(this, _XMLMultiPartUploadHelper_instances, \"m\", _XMLMultiPartUploadHelper_handleErrorResponse).call(this, e, bail);\n            }\n        }, this.retryOptions);\n    }\n    /**\n     * Uploads the provided chunk of data to the XML API using the previously created upload id.\n     *\n     * @param {number} partNumber the sequence number of this chunk.\n     * @param {Buffer} chunk the chunk of data to be uploaded.\n     * @param {string | false} validation whether or not to include the md5 hash in the headers to cause the server\n     * to validate the chunk was not corrupted.\n     * @returns {Promise<void>}\n     */\n    async uploadPart(partNumber, chunk, validation) {\n        const url = `${this.baseUrl}?partNumber=${partNumber}&uploadId=${this.uploadId}`;\n        let headers = __classPrivateFieldGet(this, _XMLMultiPartUploadHelper_instances, \"m\", _XMLMultiPartUploadHelper_setGoogApiClientHeaders).call(this);\n        if (validation === 'md5') {\n            const hash = (0, crypto_1.createHash)('md5').update(chunk).digest('base64');\n            headers = {\n                'Content-MD5': hash,\n            };\n        }\n        return (0, async_retry_1.default)(async (bail) => {\n            try {\n                const res = await this.authClient.request({\n                    url,\n                    method: 'PUT',\n                    body: chunk,\n                    headers,\n                });\n                if (res.data && res.data.error) {\n                    throw res.data.error;\n                }\n                this.partsMap.set(partNumber, res.headers['etag']);\n            }\n            catch (e) {\n                __classPrivateFieldGet(this, _XMLMultiPartUploadHelper_instances, \"m\", _XMLMultiPartUploadHelper_handleErrorResponse).call(this, e, bail);\n            }\n        }, this.retryOptions);\n    }\n    /**\n     * Sends the final request of the MPU to tell GCS the upload is now complete.\n     *\n     * @returns {Promise<void>}\n     */\n    async completeUpload() {\n        const url = `${this.baseUrl}?uploadId=${this.uploadId}`;\n        const sortedMap = new Map([...this.partsMap.entries()].sort((a, b) => a[0] - b[0]));\n        const parts = [];\n        for (const entry of sortedMap.entries()) {\n            parts.push({ PartNumber: entry[0], ETag: entry[1] });\n        }\n        const body = `<CompleteMultipartUpload>${this.xmlBuilder.build(parts)}</CompleteMultipartUpload>`;\n        return (0, async_retry_1.default)(async (bail) => {\n            try {\n                const res = await this.authClient.request({\n                    headers: __classPrivateFieldGet(this, _XMLMultiPartUploadHelper_instances, \"m\", _XMLMultiPartUploadHelper_setGoogApiClientHeaders).call(this),\n                    url,\n                    method: 'POST',\n                    body,\n                });\n                if (res.data && res.data.error) {\n                    throw res.data.error;\n                }\n                return res;\n            }\n            catch (e) {\n                __classPrivateFieldGet(this, _XMLMultiPartUploadHelper_instances, \"m\", _XMLMultiPartUploadHelper_handleErrorResponse).call(this, e, bail);\n                return;\n            }\n        }, this.retryOptions);\n    }\n    /**\n     * Aborts an multipart upload that is in progress. Once aborted, any parts in the process of being uploaded fail,\n     * and future requests using the upload ID fail.\n     *\n     * @returns {Promise<void>}\n     */\n    async abortUpload() {\n        const url = `${this.baseUrl}?uploadId=${this.uploadId}`;\n        return (0, async_retry_1.default)(async (bail) => {\n            try {\n                const res = await this.authClient.request({\n                    url,\n                    method: 'DELETE',\n                });\n                if (res.data && res.data.error) {\n                    throw res.data.error;\n                }\n            }\n            catch (e) {\n                __classPrivateFieldGet(this, _XMLMultiPartUploadHelper_instances, \"m\", _XMLMultiPartUploadHelper_handleErrorResponse).call(this, e, bail);\n                return;\n            }\n        }, this.retryOptions);\n    }\n}\n_XMLMultiPartUploadHelper_instances = new WeakSet(), _XMLMultiPartUploadHelper_setGoogApiClientHeaders = function _XMLMultiPartUploadHelper_setGoogApiClientHeaders(headers = {}) {\n    let headerFound = false;\n    let userAgentFound = false;\n    for (const [key, value] of Object.entries(headers)) {\n        if (key.toLocaleLowerCase().trim() === 'x-goog-api-client') {\n            headerFound = true;\n            // Prepend command feature to value, if not already there\n            if (!value.includes(GCCL_GCS_CMD_FEATURE.UPLOAD_SHARDED)) {\n                headers[key] =\n                    `${value} gccl-gcs-cmd/${GCCL_GCS_CMD_FEATURE.UPLOAD_SHARDED}`;\n            }\n        }\n        else if (key.toLocaleLowerCase().trim() === 'user-agent') {\n            userAgentFound = true;\n        }\n    }\n    // If the header isn't present, add it\n    if (!headerFound) {\n        headers['x-goog-api-client'] = `${(0, util_js_2.getRuntimeTrackingString)()} gccl/${packageJson.version} gccl-gcs-cmd/${GCCL_GCS_CMD_FEATURE.UPLOAD_SHARDED}`;\n    }\n    // If the User-Agent isn't present, add it\n    if (!userAgentFound) {\n        headers['User-Agent'] = (0, util_js_2.getUserAgentString)();\n    }\n    return headers;\n}, _XMLMultiPartUploadHelper_handleErrorResponse = function _XMLMultiPartUploadHelper_handleErrorResponse(err, bail) {\n    if (this.bucket.storage.retryOptions.autoRetry &&\n        this.bucket.storage.retryOptions.retryableErrorFn(err)) {\n        throw err;\n    }\n    else {\n        bail(err);\n    }\n};\n/**\n * Create a TransferManager object to perform parallel transfer operations on a Cloud Storage bucket.\n *\n * @class\n * @hideconstructor\n *\n * @param {Bucket} bucket A {@link Bucket} instance\n *\n */\nclass TransferManager {\n    constructor(bucket) {\n        this.bucket = bucket;\n    }\n    /**\n     * @typedef {object} UploadManyFilesOptions\n     * @property {number} [concurrencyLimit] The number of concurrently executing promises\n     * to use when uploading the files.\n     * @property {Function} [customDestinationBuilder] A fuction that will take the current path of a local file\n     * and return a string representing a custom path to be used to upload the file to GCS.\n     * @property {boolean} [skipIfExists] Do not upload the file if it already exists in\n     * the bucket. This will set the precondition ifGenerationMatch = 0.\n     * @property {string} [prefix] A prefix to append to all of the uploaded files.\n     * @property {object} [passthroughOptions] {@link UploadOptions} Options to be passed through\n     * to each individual upload operation.\n     *\n     */\n    /**\n     * Upload multiple files in parallel to the bucket. This is a convenience method\n     * that utilizes {@link Bucket#upload} to perform the upload.\n     *\n     * @param {array | string} [filePathsOrDirectory] An array of fully qualified paths to the files or a directory name.\n     * If a directory name is provided, the directory will be recursively walked and all files will be added to the upload list.\n     * to be uploaded to the bucket\n     * @param {UploadManyFilesOptions} [options] Configuration options.\n     * @returns {Promise<UploadResponse[]>}\n     *\n     * @example\n     * ```\n     * const {Storage} = require('@google-cloud/storage');\n     * const storage = new Storage();\n     * const bucket = storage.bucket('my-bucket');\n     * const transferManager = new TransferManager(bucket);\n     *\n     * //-\n     * // Upload multiple files in parallel.\n     * //-\n     * const response = await transferManager.uploadManyFiles(['/local/path/file1.txt, 'local/path/file2.txt']);\n     * // Your bucket now contains:\n     * // - \"local/path/file1.txt\" (with the contents of '/local/path/file1.txt')\n     * // - \"local/path/file2.txt\" (with the contents of '/local/path/file2.txt')\n     * const response = await transferManager.uploadManyFiles('/local/directory');\n     * // Your bucket will now contain all files contained in '/local/directory' maintaining the subdirectory structure.\n     * ```\n     *\n     */\n    async uploadManyFiles(filePathsOrDirectory, options = {}) {\n        var _a;\n        if (options.skipIfExists && ((_a = options.passthroughOptions) === null || _a === void 0 ? void 0 : _a.preconditionOpts)) {\n            options.passthroughOptions.preconditionOpts.ifGenerationMatch = 0;\n        }\n        else if (options.skipIfExists &&\n            options.passthroughOptions === undefined) {\n            options.passthroughOptions = {\n                preconditionOpts: {\n                    ifGenerationMatch: 0,\n                },\n            };\n        }\n        const limit = (0, p_limit_1.default)(options.concurrencyLimit || DEFAULT_PARALLEL_UPLOAD_LIMIT);\n        const promises = [];\n        let allPaths = [];\n        if (!Array.isArray(filePathsOrDirectory)) {\n            for await (const curPath of this.getPathsFromDirectory(filePathsOrDirectory)) {\n                allPaths.push(curPath);\n            }\n        }\n        else {\n            allPaths = filePathsOrDirectory;\n        }\n        for (const filePath of allPaths) {\n            const stat = await fs_1.promises.lstat(filePath);\n            if (stat.isDirectory()) {\n                continue;\n            }\n            const passThroughOptionsCopy = {\n                ...options.passthroughOptions,\n                [util_js_1.GCCL_GCS_CMD_KEY]: GCCL_GCS_CMD_FEATURE.UPLOAD_MANY,\n            };\n            passThroughOptionsCopy.destination = options.customDestinationBuilder\n                ? options.customDestinationBuilder(filePath, options)\n                : filePath.split(path.sep).join(path.posix.sep);\n            if (options.prefix) {\n                passThroughOptionsCopy.destination = path.posix.join(...options.prefix.split(path.sep), passThroughOptionsCopy.destination);\n            }\n            promises.push(limit(() => this.bucket.upload(filePath, passThroughOptionsCopy)));\n        }\n        return Promise.all(promises);\n    }\n    /**\n     * @typedef {object} DownloadManyFilesOptions\n     * @property {number} [concurrencyLimit] The number of concurrently executing promises\n     * to use when downloading the files.\n     * @property {string} [prefix] A prefix to append to all of the downloaded files.\n     * @property {string} [stripPrefix] A prefix to remove from all of the downloaded files.\n     * @property {object} [passthroughOptions] {@link DownloadOptions} Options to be passed through\n     * to each individual download operation.\n     * @property {boolean} [skipIfExists] Do not download the file if it already exists in\n     * the destination.\n     *\n     */\n    /**\n     * Download multiple files in parallel to the local filesystem. This is a convenience method\n     * that utilizes {@link File#download} to perform the download.\n     *\n     * @param {array | string} [filesOrFolder] An array of file name strings or file objects to be downloaded. If\n     * a string is provided this will be treated as a GCS prefix and all files with that prefix will be downloaded.\n     * @param {DownloadManyFilesOptions} [options] Configuration options. Setting options.prefix or options.stripPrefix\n     * or options.passthroughOptions.destination will cause the downloaded files to be written to the file system\n     * instead of being returned as a buffer.\n     * @returns {Promise<DownloadResponse[]>}\n     *\n     * @example\n     * ```\n     * const {Storage} = require('@google-cloud/storage');\n     * const storage = new Storage();\n     * const bucket = storage.bucket('my-bucket');\n     * const transferManager = new TransferManager(bucket);\n     *\n     * //-\n     * // Download multiple files in parallel.\n     * //-\n     * const response = await transferManager.downloadManyFiles(['file1.txt', 'file2.txt']);\n     * // The following files have been downloaded:\n     * // - \"file1.txt\" (with the contents from my-bucket.file1.txt)\n     * // - \"file2.txt\" (with the contents from my-bucket.file2.txt)\n     * const response = await transferManager.downloadManyFiles([bucket.File('file1.txt'), bucket.File('file2.txt')]);\n     * // The following files have been downloaded:\n     * // - \"file1.txt\" (with the contents from my-bucket.file1.txt)\n     * // - \"file2.txt\" (with the contents from my-bucket.file2.txt)\n     * const response = await transferManager.downloadManyFiles('test-folder');\n     * // All files with GCS prefix of 'test-folder' have been downloaded.\n     * ```\n     *\n     */\n    async downloadManyFiles(filesOrFolder, options = {}) {\n        const limit = (0, p_limit_1.default)(options.concurrencyLimit || DEFAULT_PARALLEL_DOWNLOAD_LIMIT);\n        const promises = [];\n        let files = [];\n        if (!Array.isArray(filesOrFolder)) {\n            const directoryFiles = await this.bucket.getFiles({\n                prefix: filesOrFolder,\n            });\n            files = directoryFiles[0];\n        }\n        else {\n            files = filesOrFolder.map(curFile => {\n                if (typeof curFile === 'string') {\n                    return this.bucket.file(curFile);\n                }\n                return curFile;\n            });\n        }\n        const stripRegexString = options.stripPrefix\n            ? `^${options.stripPrefix}`\n            : EMPTY_REGEX;\n        const regex = new RegExp(stripRegexString, 'g');\n        for (const file of files) {\n            const passThroughOptionsCopy = {\n                ...options.passthroughOptions,\n                [util_js_1.GCCL_GCS_CMD_KEY]: GCCL_GCS_CMD_FEATURE.DOWNLOAD_MANY,\n            };\n            if (options.prefix || passThroughOptionsCopy.destination) {\n                passThroughOptionsCopy.destination = path.join(options.prefix || '', passThroughOptionsCopy.destination || '', file.name);\n            }\n            if (options.stripPrefix) {\n                passThroughOptionsCopy.destination = file.name.replace(regex, '');\n            }\n            if (options.skipIfExists &&\n                (0, fs_1.existsSync)(passThroughOptionsCopy.destination || '')) {\n                continue;\n            }\n            promises.push(limit(async () => {\n                const destination = passThroughOptionsCopy.destination;\n                if (destination && destination.endsWith(path.sep)) {\n                    await fs_1.promises.mkdir(destination, { recursive: true });\n                    return Promise.resolve([\n                        Buffer.alloc(0),\n                    ]);\n                }\n                return file.download(passThroughOptionsCopy);\n            }));\n        }\n        return Promise.all(promises);\n    }\n    /**\n     * @typedef {object} DownloadFileInChunksOptions\n     * @property {number} [concurrencyLimit] The number of concurrently executing promises\n     * to use when downloading the file.\n     * @property {number} [chunkSizeBytes] The size in bytes of each chunk to be downloaded.\n     * @property {string | boolean} [validation] Whether or not to perform a CRC32C validation check when download is complete.\n     * @property {boolean} [noReturnData] Whether or not to return the downloaded data. A `true` value here would be useful for files with a size that will not fit into memory.\n     *\n     */\n    /**\n     * Download a large file in chunks utilizing parallel download operations. This is a convenience method\n     * that utilizes {@link File#download} to perform the download.\n     *\n     * @param {File | string} fileOrName {@link File} to download.\n     * @param {DownloadFileInChunksOptions} [options] Configuration options.\n     * @returns {Promise<void | DownloadResponse>}\n     *\n     * @example\n     * ```\n     * const {Storage} = require('@google-cloud/storage');\n     * const storage = new Storage();\n     * const bucket = storage.bucket('my-bucket');\n     * const transferManager = new TransferManager(bucket);\n     *\n     * //-\n     * // Download a large file in chunks utilizing parallel operations.\n     * //-\n     * const response = await transferManager.downloadFileInChunks(bucket.file('large-file.txt');\n     * // Your local directory now contains:\n     * // - \"large-file.txt\" (with the contents from my-bucket.large-file.txt)\n     * ```\n     *\n     */\n    async downloadFileInChunks(fileOrName, options = {}) {\n        let chunkSize = options.chunkSizeBytes || DOWNLOAD_IN_CHUNKS_DEFAULT_CHUNK_SIZE;\n        let limit = (0, p_limit_1.default)(options.concurrencyLimit || DEFAULT_PARALLEL_CHUNKED_DOWNLOAD_LIMIT);\n        const noReturnData = Boolean(options.noReturnData);\n        const promises = [];\n        const file = typeof fileOrName === 'string'\n            ? this.bucket.file(fileOrName)\n            : fileOrName;\n        const fileInfo = await file.get();\n        const size = parseInt(fileInfo[0].metadata.size.toString());\n        // If the file size does not meet the threshold download it as a single chunk.\n        if (size < DOWNLOAD_IN_CHUNKS_FILE_SIZE_THRESHOLD) {\n            limit = (0, p_limit_1.default)(1);\n            chunkSize = size;\n        }\n        let start = 0;\n        const filePath = options.destination || path.basename(file.name);\n        const fileToWrite = await fs_1.promises.open(filePath, 'w');\n        while (start < size) {\n            const chunkStart = start;\n            let chunkEnd = start + chunkSize - 1;\n            chunkEnd = chunkEnd > size ? size : chunkEnd;\n            promises.push(limit(async () => {\n                const resp = await file.download({\n                    start: chunkStart,\n                    end: chunkEnd,\n                    [util_js_1.GCCL_GCS_CMD_KEY]: GCCL_GCS_CMD_FEATURE.DOWNLOAD_SHARDED,\n                });\n                const result = await fileToWrite.write(resp[0], 0, resp[0].length, chunkStart);\n                if (noReturnData)\n                    return;\n                return result.buffer;\n            }));\n            start += chunkSize;\n        }\n        let chunks;\n        try {\n            chunks = await Promise.all(promises);\n        }\n        finally {\n            await fileToWrite.close();\n        }\n        if (options.validation === 'crc32c' && fileInfo[0].metadata.crc32c) {\n            const downloadedCrc32C = await crc32c_js_1.CRC32C.fromFile(filePath);\n            if (!downloadedCrc32C.validate(fileInfo[0].metadata.crc32c)) {\n                const mismatchError = new file_js_1.RequestError(file_js_1.FileExceptionMessages.DOWNLOAD_MISMATCH);\n                mismatchError.code = 'CONTENT_DOWNLOAD_MISMATCH';\n                throw mismatchError;\n            }\n        }\n        if (noReturnData)\n            return;\n        return [Buffer.concat(chunks, size)];\n    }\n    /**\n     * @typedef {object} UploadFileInChunksOptions\n     * @property {number} [concurrencyLimit] The number of concurrently executing promises\n     * to use when uploading the file.\n     * @property {number} [chunkSizeBytes] The size in bytes of each chunk to be uploaded.\n     * @property {string} [uploadName] Name of the file when saving to GCS. If ommitted the name is taken from the file path.\n     * @property {number} [maxQueueSize] The number of chunks to be uploaded to hold in memory concurrently. If not specified\n     * defaults to the specified concurrency limit.\n     * @property {string} [uploadId] If specified attempts to resume a previous upload.\n     * @property {Map} [partsMap] If specified alongside uploadId, attempts to resume a previous upload from the last chunk\n     * specified in partsMap\n     * @property {object} [headers] headers to be sent when initiating the multipart upload.\n     * See {@link https://cloud.google.com/storage/docs/xml-api/post-object-multipart#request_headers| Request Headers: Initiate a Multipart Upload}\n     * @property {boolean} [autoAbortFailure] boolean to indicate if an in progress upload session will be automatically aborted upon failure. If not set,\n     * failures will be automatically aborted.\n     *\n     */\n    /**\n     * Upload a large file in chunks utilizing parallel upload opertions. If the upload fails, an uploadId and\n     * map containing all the successfully uploaded parts will be returned to the caller. These arguments can be used to\n     * resume the upload.\n     *\n     * @param {string} [filePath] The path of the file to be uploaded\n     * @param {UploadFileInChunksOptions} [options] Configuration options.\n     * @param {MultiPartHelperGenerator} [generator] A function that will return a type that implements the MPU interface. Most users will not need to use this.\n     * @returns {Promise<void>} If successful a promise resolving to void, otherwise a error containing the message, uploadid, and parts map.\n     *\n     * @example\n     * ```\n     * const {Storage} = require('@google-cloud/storage');\n     * const storage = new Storage();\n     * const bucket = storage.bucket('my-bucket');\n     * const transferManager = new TransferManager(bucket);\n     *\n     * //-\n     * // Upload a large file in chunks utilizing parallel operations.\n     * //-\n     * const response = await transferManager.uploadFileInChunks('large-file.txt');\n     * // Your bucket now contains:\n     * // - \"large-file.txt\"\n     * ```\n     *\n     *\n     */\n    async uploadFileInChunks(filePath, options = {}, generator = defaultMultiPartGenerator) {\n        const chunkSize = options.chunkSizeBytes || UPLOAD_IN_CHUNKS_DEFAULT_CHUNK_SIZE;\n        const limit = (0, p_limit_1.default)(options.concurrencyLimit || DEFAULT_PARALLEL_CHUNKED_UPLOAD_LIMIT);\n        const maxQueueSize = options.maxQueueSize ||\n            options.concurrencyLimit ||\n            DEFAULT_PARALLEL_CHUNKED_UPLOAD_LIMIT;\n        const fileName = options.uploadName || path.basename(filePath);\n        const mpuHelper = generator(this.bucket, fileName, options.uploadId, options.partsMap);\n        let partNumber = 1;\n        let promises = [];\n        try {\n            if (options.uploadId === undefined) {\n                await mpuHelper.initiateUpload(options.headers);\n            }\n            const startOrResumptionByte = mpuHelper.partsMap.size * chunkSize;\n            const readStream = (0, fs_1.createReadStream)(filePath, {\n                highWaterMark: chunkSize,\n                start: startOrResumptionByte,\n            });\n            // p-limit only limits the number of running promises. We do not want to hold an entire\n            // large file in memory at once so promises acts a queue that will hold only maxQueueSize in memory.\n            for await (const curChunk of readStream) {\n                if (promises.length >= maxQueueSize) {\n                    await Promise.all(promises);\n                    promises = [];\n                }\n                promises.push(limit(() => mpuHelper.uploadPart(partNumber++, curChunk, options.validation)));\n            }\n            await Promise.all(promises);\n            return await mpuHelper.completeUpload();\n        }\n        catch (e) {\n            if ((options.autoAbortFailure === undefined || options.autoAbortFailure) &&\n                mpuHelper.uploadId) {\n                try {\n                    await mpuHelper.abortUpload();\n                    return;\n                }\n                catch (e) {\n                    throw new MultiPartUploadError(e.message, mpuHelper.uploadId, mpuHelper.partsMap);\n                }\n            }\n            throw new MultiPartUploadError(e.message, mpuHelper.uploadId, mpuHelper.partsMap);\n        }\n    }\n    async *getPathsFromDirectory(directory) {\n        const filesAndSubdirectories = await fs_1.promises.readdir(directory, {\n            withFileTypes: true,\n        });\n        for (const curFileOrDirectory of filesAndSubdirectories) {\n            const fullPath = path.join(directory, curFileOrDirectory.name);\n            curFileOrDirectory.isDirectory()\n                ? yield* this.getPathsFromDirectory(fullPath)\n                : yield fullPath;\n        }\n    }\n}\nexports.TransferManager = TransferManager;\n"],"mappings":"AAAA,YAAY;;AACZ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAIA,eAAe,GAAI,IAAI,IAAI,IAAI,CAACA,eAAe,KAAMC,MAAM,CAACC,MAAM,GAAI,UAASC,CAAC,EAAEC,CAAC,EAAEC,CAAC,EAAEC,EAAE,EAAE;EAC5F,IAAIA,EAAE,KAAKC,SAAS,EAAED,EAAE,GAAGD,CAAC;EAC5B,IAAIG,IAAI,GAAGP,MAAM,CAACQ,wBAAwB,CAACL,CAAC,EAAEC,CAAC,CAAC;EAChD,IAAI,CAACG,IAAI,KAAK,KAAK,IAAIA,IAAI,GAAG,CAACJ,CAAC,CAACM,UAAU,GAAGF,IAAI,CAACG,QAAQ,IAAIH,IAAI,CAACI,YAAY,CAAC,EAAE;IACjFJ,IAAI,GAAG;MAAEK,UAAU,EAAE,IAAI;MAAEC,GAAG,EAAE,YAAW;QAAE,OAAOV,CAAC,CAACC,CAAC,CAAC;MAAE;IAAE,CAAC;EAC/D;EACAJ,MAAM,CAACc,cAAc,CAACZ,CAAC,EAAEG,EAAE,EAAEE,IAAI,CAAC;AACtC,CAAC,GAAK,UAASL,CAAC,EAAEC,CAAC,EAAEC,CAAC,EAAEC,EAAE,EAAE;EACxB,IAAIA,EAAE,KAAKC,SAAS,EAAED,EAAE,GAAGD,CAAC;EAC5BF,CAAC,CAACG,EAAE,CAAC,GAAGF,CAAC,CAACC,CAAC,CAAC;AAChB,CAAE,CAAC;AACH,IAAIW,kBAAkB,GAAI,IAAI,IAAI,IAAI,CAACA,kBAAkB,KAAMf,MAAM,CAACC,MAAM,GAAI,UAASC,CAAC,EAAEc,CAAC,EAAE;EAC3FhB,MAAM,CAACc,cAAc,CAACZ,CAAC,EAAE,SAAS,EAAE;IAAEU,UAAU,EAAE,IAAI;IAAEK,KAAK,EAAED;EAAE,CAAC,CAAC;AACvE,CAAC,GAAI,UAASd,CAAC,EAAEc,CAAC,EAAE;EAChBd,CAAC,CAAC,SAAS,CAAC,GAAGc,CAAC;AACpB,CAAC,CAAC;AACF,IAAIE,YAAY,GAAI,IAAI,IAAI,IAAI,CAACA,YAAY,IAAK,UAAUC,GAAG,EAAE;EAC7D,IAAIA,GAAG,IAAIA,GAAG,CAACV,UAAU,EAAE,OAAOU,GAAG;EACrC,IAAIC,MAAM,GAAG,CAAC,CAAC;EACf,IAAID,GAAG,IAAI,IAAI,EAAE,KAAK,IAAIf,CAAC,IAAIe,GAAG,EAAE,IAAIf,CAAC,KAAK,SAAS,IAAIJ,MAAM,CAACqB,SAAS,CAACC,cAAc,CAACC,IAAI,CAACJ,GAAG,EAAEf,CAAC,CAAC,EAAEL,eAAe,CAACqB,MAAM,EAAED,GAAG,EAAEf,CAAC,CAAC;EACxIW,kBAAkB,CAACK,MAAM,EAAED,GAAG,CAAC;EAC/B,OAAOC,MAAM;AACjB,CAAC;AACD,IAAII,sBAAsB,GAAI,IAAI,IAAI,IAAI,CAACA,sBAAsB,IAAK,UAAUC,QAAQ,EAAEC,KAAK,EAAEC,IAAI,EAAEC,CAAC,EAAE;EACtG,IAAID,IAAI,KAAK,GAAG,IAAI,CAACC,CAAC,EAAE,MAAM,IAAIC,SAAS,CAAC,+CAA+C,CAAC;EAC5F,IAAI,OAAOH,KAAK,KAAK,UAAU,GAAGD,QAAQ,KAAKC,KAAK,IAAI,CAACE,CAAC,GAAG,CAACF,KAAK,CAACI,GAAG,CAACL,QAAQ,CAAC,EAAE,MAAM,IAAII,SAAS,CAAC,0EAA0E,CAAC;EAClL,OAAOF,IAAI,KAAK,GAAG,GAAGC,CAAC,GAAGD,IAAI,KAAK,GAAG,GAAGC,CAAC,CAACL,IAAI,CAACE,QAAQ,CAAC,GAAGG,CAAC,GAAGA,CAAC,CAACX,KAAK,GAAGS,KAAK,CAACb,GAAG,CAACY,QAAQ,CAAC;AACjG,CAAC;AACD,IAAIM,eAAe,GAAI,IAAI,IAAI,IAAI,CAACA,eAAe,IAAK,UAAUZ,GAAG,EAAE;EACnE,OAAQA,GAAG,IAAIA,GAAG,CAACV,UAAU,GAAIU,GAAG,GAAG;IAAE,SAAS,EAAEA;EAAI,CAAC;AAC7D,CAAC;AACD,IAAIa,mCAAmC,EAAEC,iDAAiD,EAAEC,6CAA6C;AACzIlC,MAAM,CAACc,cAAc,CAACqB,OAAO,EAAE,YAAY,EAAE;EAAElB,KAAK,EAAE;AAAK,CAAC,CAAC;AAC7DkB,OAAO,CAACC,eAAe,GAAGD,OAAO,CAACE,oBAAoB,GAAG,KAAK,CAAC;AAC/D,MAAMC,SAAS,GAAGC,OAAO,CAAC,WAAW,CAAC;AACtC,MAAMC,SAAS,GAAGT,eAAe,CAACQ,OAAO,CAAC,SAAS,CAAC,CAAC;AACrD,MAAME,IAAI,GAAGvB,YAAY,CAACqB,OAAO,CAAC,MAAM,CAAC,CAAC;AAC1C,MAAMG,IAAI,GAAGH,OAAO,CAAC,IAAI,CAAC;AAC1B,MAAMI,WAAW,GAAGJ,OAAO,CAAC,aAAa,CAAC;AAC1C,MAAMK,qBAAqB,GAAGL,OAAO,CAAC,qBAAqB,CAAC;AAC5D,MAAMM,iBAAiB,GAAGN,OAAO,CAAC,iBAAiB,CAAC;AACpD,MAAMO,aAAa,GAAGf,eAAe,CAACQ,OAAO,CAAC,aAAa,CAAC,CAAC;AAC7D,MAAMQ,QAAQ,GAAGR,OAAO,CAAC,QAAQ,CAAC;AAClC,MAAMS,SAAS,GAAGT,OAAO,CAAC,yBAAyB,CAAC;AACpD,MAAMU,SAAS,GAAGV,OAAO,CAAC,WAAW,CAAC;AACtC;AACA;AACA,MAAMW,yBAAyB,GAAGX,OAAO,CAAC,2BAA2B,CAAC;AACtE,MAAMY,WAAW,GAAG,CAAC,CAAC,EAAED,yBAAyB,CAACE,cAAc,GAAG;AACnE;AACA;AACA;AACA;AACA,MAAMC,6BAA6B,GAAG,CAAC;AACvC;AACA;AACA;AACA;AACA,MAAMC,+BAA+B,GAAG,CAAC;AACzC;AACA;AACA;AACA;AACA,MAAMC,uCAAuC,GAAG,CAAC;AACjD;AACA;AACA;AACA;AACA,MAAMC,sCAAsC,GAAG,EAAE,GAAG,IAAI,GAAG,IAAI;AAC/D;AACA;AACA;AACA;AACA,MAAMC,qCAAqC,GAAG,EAAE,GAAG,IAAI,GAAG,IAAI;AAC9D;AACA;AACA;AACA;AACA,MAAMC,mCAAmC,GAAG,EAAE,GAAG,IAAI,GAAG,IAAI;AAC5D;AACA;AACA;AACA;AACA,MAAMC,qCAAqC,GAAG,CAAC;AAC/C,MAAMC,WAAW,GAAG,MAAM;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAMC,oBAAoB,GAAG;EACzBC,WAAW,EAAE,gBAAgB;EAC7BC,aAAa,EAAE,kBAAkB;EACjCC,cAAc,EAAE,mBAAmB;EACnCC,gBAAgB,EAAE;AACtB,CAAC;AACD,MAAMC,yBAAyB,GAAG,CAACC,MAAM,EAAEC,QAAQ,EAAEC,QAAQ,EAAEC,QAAQ,KAAK;EACxE,OAAO,IAAIC,wBAAwB,CAACJ,MAAM,EAAEC,QAAQ,EAAEC,QAAQ,EAAEC,QAAQ,CAAC;AAC7E,CAAC;AACD,MAAMjC,oBAAoB,SAASmC,KAAK,CAAC;EACrCC,WAAW,CAACC,OAAO,EAAEL,QAAQ,EAAEC,QAAQ,EAAE;IACrC,KAAK,CAACI,OAAO,CAAC;IACd,IAAI,CAACL,QAAQ,GAAGA,QAAQ;IACxB,IAAI,CAACC,QAAQ,GAAGA,QAAQ;EAC5B;AACJ;AACAnC,OAAO,CAACE,oBAAoB,GAAGA,oBAAoB;AACnD;AACA;AACA;AACA;AACA;AACA;AACA,MAAMkC,wBAAwB,CAAC;EAC3BE,WAAW,CAACN,MAAM,EAAEC,QAAQ,EAAEC,QAAQ,EAAEC,QAAQ,EAAE;IAC9CtC,mCAAmC,CAAC2C,GAAG,CAAC,IAAI,CAAC;IAC7C,IAAI,CAACC,UAAU,GAAGT,MAAM,CAACU,OAAO,CAACD,UAAU,IAAI,IAAIhC,qBAAqB,CAACkC,UAAU,EAAE;IACrF,IAAI,CAACT,QAAQ,GAAGA,QAAQ,IAAI,EAAE;IAC9B,IAAI,CAACF,MAAM,GAAGA,MAAM;IACpB,IAAI,CAACC,QAAQ,GAAGA,QAAQ;IACxB,IAAI,CAACW,OAAO,GAAI,WAAUZ,MAAM,CAACa,IAAK,IAAG,IAAIC,GAAG,CAAC,IAAI,CAACd,MAAM,CAACU,OAAO,CAACK,WAAW,CAAC,CAACC,QAAS,IAAGf,QAAS,EAAC;IACxG,IAAI,CAACgB,UAAU,GAAG,IAAIvC,iBAAiB,CAACwC,UAAU,CAAC;MAAEC,aAAa,EAAE;IAAO,CAAC,CAAC;IAC7E,IAAI,CAACC,SAAS,GAAG,IAAI1C,iBAAiB,CAAC2C,SAAS,EAAE;IAClD,IAAI,CAAClB,QAAQ,GAAGA,QAAQ,IAAI,IAAImB,GAAG,EAAE;IACrC,IAAI,CAACC,YAAY,GAAG;MAChBC,OAAO,EAAE,IAAI,CAACxB,MAAM,CAACU,OAAO,CAACa,YAAY,CAACE,UAAU;MACpDC,MAAM,EAAE,IAAI,CAAC1B,MAAM,CAACU,OAAO,CAACa,YAAY,CAACI,oBAAoB;MAC7DC,UAAU,EAAE,IAAI,CAAC5B,MAAM,CAACU,OAAO,CAACa,YAAY,CAACM,aAAa,GAAG,IAAI;MACjEC,YAAY,EAAE,IAAI,CAAC9B,MAAM,CAACU,OAAO,CAACa,YAAY,CAACQ,YAAY,GAAG;IAClE,CAAC;EACL;EACA;AACJ;AACA;AACA;AACA;EACI,MAAMC,cAAc,GAAe;IAAA,IAAdC,OAAO,uEAAG,CAAC,CAAC;IAC7B,MAAMC,GAAG,GAAI,GAAE,IAAI,CAACtB,OAAQ,UAAS;IACrC,OAAO,CAAC,CAAC,EAAEjC,aAAa,CAACwD,OAAO,EAAE,MAAOC,IAAI,IAAK;MAC9C,IAAI;QACA,MAAMC,GAAG,GAAG,MAAM,IAAI,CAAC5B,UAAU,CAAC6B,OAAO,CAAC;UACtCL,OAAO,EAAE5E,sBAAsB,CAAC,IAAI,EAAEQ,mCAAmC,EAAE,GAAG,EAAEC,iDAAiD,CAAC,CAACV,IAAI,CAAC,IAAI,EAAE6E,OAAO,CAAC;UACtJM,MAAM,EAAE,MAAM;UACdL;QACJ,CAAC,CAAC;QACF,IAAIG,GAAG,CAACG,IAAI,IAAIH,GAAG,CAACG,IAAI,CAACC,KAAK,EAAE;UAC5B,MAAMJ,GAAG,CAACG,IAAI,CAACC,KAAK;QACxB;QACA,MAAMC,SAAS,GAAG,IAAI,CAACtB,SAAS,CAACuB,KAAK,CAACN,GAAG,CAACG,IAAI,CAAC;QAChD,IAAI,CAACtC,QAAQ,GAAGwC,SAAS,CAACE,6BAA6B,CAACC,QAAQ;MACpE,CAAC,CACD,OAAOC,CAAC,EAAE;QACNzF,sBAAsB,CAAC,IAAI,EAAEQ,mCAAmC,EAAE,GAAG,EAAEE,6CAA6C,CAAC,CAACX,IAAI,CAAC,IAAI,EAAE0F,CAAC,EAAEV,IAAI,CAAC;MAC7I;IACJ,CAAC,EAAE,IAAI,CAACb,YAAY,CAAC;EACzB;EACA;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;EACI,MAAMwB,UAAU,CAACC,UAAU,EAAEC,KAAK,EAAEC,UAAU,EAAE;IAC5C,MAAMhB,GAAG,GAAI,GAAE,IAAI,CAACtB,OAAQ,eAAcoC,UAAW,aAAY,IAAI,CAAC9C,QAAS,EAAC;IAChF,IAAI+B,OAAO,GAAG5E,sBAAsB,CAAC,IAAI,EAAEQ,mCAAmC,EAAE,GAAG,EAAEC,iDAAiD,CAAC,CAACV,IAAI,CAAC,IAAI,CAAC;IAClJ,IAAI8F,UAAU,KAAK,KAAK,EAAE;MACtB,MAAMC,IAAI,GAAG,CAAC,CAAC,EAAEvE,QAAQ,CAACwE,UAAU,EAAE,KAAK,CAAC,CAACC,MAAM,CAACJ,KAAK,CAAC,CAACK,MAAM,CAAC,QAAQ,CAAC;MAC3ErB,OAAO,GAAG;QACN,aAAa,EAAEkB;MACnB,CAAC;IACL;IACA,OAAO,CAAC,CAAC,EAAExE,aAAa,CAACwD,OAAO,EAAE,MAAOC,IAAI,IAAK;MAC9C,IAAI;QACA,MAAMC,GAAG,GAAG,MAAM,IAAI,CAAC5B,UAAU,CAAC6B,OAAO,CAAC;UACtCJ,GAAG;UACHK,MAAM,EAAE,KAAK;UACbgB,IAAI,EAAEN,KAAK;UACXhB;QACJ,CAAC,CAAC;QACF,IAAII,GAAG,CAACG,IAAI,IAAIH,GAAG,CAACG,IAAI,CAACC,KAAK,EAAE;UAC5B,MAAMJ,GAAG,CAACG,IAAI,CAACC,KAAK;QACxB;QACA,IAAI,CAACtC,QAAQ,CAACqD,GAAG,CAACR,UAAU,EAAEX,GAAG,CAACJ,OAAO,CAAC,MAAM,CAAC,CAAC;MACtD,CAAC,CACD,OAAOa,CAAC,EAAE;QACNzF,sBAAsB,CAAC,IAAI,EAAEQ,mCAAmC,EAAE,GAAG,EAAEE,6CAA6C,CAAC,CAACX,IAAI,CAAC,IAAI,EAAE0F,CAAC,EAAEV,IAAI,CAAC;MAC7I;IACJ,CAAC,EAAE,IAAI,CAACb,YAAY,CAAC;EACzB;EACA;AACJ;AACA;AACA;AACA;EACI,MAAMkC,cAAc,GAAG;IACnB,MAAMvB,GAAG,GAAI,GAAE,IAAI,CAACtB,OAAQ,aAAY,IAAI,CAACV,QAAS,EAAC;IACvD,MAAMwD,SAAS,GAAG,IAAIpC,GAAG,CAAC,CAAC,GAAG,IAAI,CAACnB,QAAQ,CAACwD,OAAO,EAAE,CAAC,CAACC,IAAI,CAAC,CAACC,CAAC,EAAEC,CAAC,KAAKD,CAAC,CAAC,CAAC,CAAC,GAAGC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;IACnF,MAAMC,KAAK,GAAG,EAAE;IAChB,KAAK,MAAMC,KAAK,IAAIN,SAAS,CAACC,OAAO,EAAE,EAAE;MACrCI,KAAK,CAACE,IAAI,CAAC;QAAEC,UAAU,EAAEF,KAAK,CAAC,CAAC,CAAC;QAAEG,IAAI,EAAEH,KAAK,CAAC,CAAC;MAAE,CAAC,CAAC;IACxD;IACA,MAAMT,IAAI,GAAI,4BAA2B,IAAI,CAACtC,UAAU,CAACmD,KAAK,CAACL,KAAK,CAAE,4BAA2B;IACjG,OAAO,CAAC,CAAC,EAAEpF,aAAa,CAACwD,OAAO,EAAE,MAAOC,IAAI,IAAK;MAC9C,IAAI;QACA,MAAMC,GAAG,GAAG,MAAM,IAAI,CAAC5B,UAAU,CAAC6B,OAAO,CAAC;UACtCL,OAAO,EAAE5E,sBAAsB,CAAC,IAAI,EAAEQ,mCAAmC,EAAE,GAAG,EAAEC,iDAAiD,CAAC,CAACV,IAAI,CAAC,IAAI,CAAC;UAC7I8E,GAAG;UACHK,MAAM,EAAE,MAAM;UACdgB;QACJ,CAAC,CAAC;QACF,IAAIlB,GAAG,CAACG,IAAI,IAAIH,GAAG,CAACG,IAAI,CAACC,KAAK,EAAE;UAC5B,MAAMJ,GAAG,CAACG,IAAI,CAACC,KAAK;QACxB;QACA,OAAOJ,GAAG;MACd,CAAC,CACD,OAAOS,CAAC,EAAE;QACNzF,sBAAsB,CAAC,IAAI,EAAEQ,mCAAmC,EAAE,GAAG,EAAEE,6CAA6C,CAAC,CAACX,IAAI,CAAC,IAAI,EAAE0F,CAAC,EAAEV,IAAI,CAAC;QACzI;MACJ;IACJ,CAAC,EAAE,IAAI,CAACb,YAAY,CAAC;EACzB;EACA;AACJ;AACA;AACA;AACA;AACA;EACI,MAAM8C,WAAW,GAAG;IAChB,MAAMnC,GAAG,GAAI,GAAE,IAAI,CAACtB,OAAQ,aAAY,IAAI,CAACV,QAAS,EAAC;IACvD,OAAO,CAAC,CAAC,EAAEvB,aAAa,CAACwD,OAAO,EAAE,MAAOC,IAAI,IAAK;MAC9C,IAAI;QACA,MAAMC,GAAG,GAAG,MAAM,IAAI,CAAC5B,UAAU,CAAC6B,OAAO,CAAC;UACtCJ,GAAG;UACHK,MAAM,EAAE;QACZ,CAAC,CAAC;QACF,IAAIF,GAAG,CAACG,IAAI,IAAIH,GAAG,CAACG,IAAI,CAACC,KAAK,EAAE;UAC5B,MAAMJ,GAAG,CAACG,IAAI,CAACC,KAAK;QACxB;MACJ,CAAC,CACD,OAAOK,CAAC,EAAE;QACNzF,sBAAsB,CAAC,IAAI,EAAEQ,mCAAmC,EAAE,GAAG,EAAEE,6CAA6C,CAAC,CAACX,IAAI,CAAC,IAAI,EAAE0F,CAAC,EAAEV,IAAI,CAAC;QACzI;MACJ;IACJ,CAAC,EAAE,IAAI,CAACb,YAAY,CAAC;EACzB;AACJ;AACA1D,mCAAmC,GAAG,IAAIyG,OAAO,EAAE,EAAExG,iDAAiD,GAAG,SAASA,iDAAiD,GAAe;EAAA,IAAdmE,OAAO,uEAAG,CAAC,CAAC;EAC5K,IAAIsC,WAAW,GAAG,KAAK;EACvB,IAAIC,cAAc,GAAG,KAAK;EAC1B,KAAK,MAAM,CAACC,GAAG,EAAE3H,KAAK,CAAC,IAAIjB,MAAM,CAAC8H,OAAO,CAAC1B,OAAO,CAAC,EAAE;IAChD,IAAIwC,GAAG,CAACC,iBAAiB,EAAE,CAACC,IAAI,EAAE,KAAK,mBAAmB,EAAE;MACxDJ,WAAW,GAAG,IAAI;MAClB;MACA,IAAI,CAACzH,KAAK,CAAC8H,QAAQ,CAAClF,oBAAoB,CAACG,cAAc,CAAC,EAAE;QACtDoC,OAAO,CAACwC,GAAG,CAAC,GACP,GAAE3H,KAAM,iBAAgB4C,oBAAoB,CAACG,cAAe,EAAC;MACtE;IACJ,CAAC,MACI,IAAI4E,GAAG,CAACC,iBAAiB,EAAE,CAACC,IAAI,EAAE,KAAK,YAAY,EAAE;MACtDH,cAAc,GAAG,IAAI;IACzB;EACJ;EACA;EACA,IAAI,CAACD,WAAW,EAAE;IACdtC,OAAO,CAAC,mBAAmB,CAAC,GAAI,GAAE,CAAC,CAAC,EAAEnD,SAAS,CAAC+F,wBAAwB,GAAI,SAAQ7F,WAAW,CAAC8F,OAAQ,iBAAgBpF,oBAAoB,CAACG,cAAe,EAAC;EACjK;EACA;EACA,IAAI,CAAC2E,cAAc,EAAE;IACjBvC,OAAO,CAAC,YAAY,CAAC,GAAG,CAAC,CAAC,EAAEnD,SAAS,CAACiG,kBAAkB,GAAG;EAC/D;EACA,OAAO9C,OAAO;AAClB,CAAC,EAAElE,6CAA6C,GAAG,SAASA,6CAA6C,CAACiH,GAAG,EAAE5C,IAAI,EAAE;EACjH,IAAI,IAAI,CAACpC,MAAM,CAACU,OAAO,CAACa,YAAY,CAAC0D,SAAS,IAC1C,IAAI,CAACjF,MAAM,CAACU,OAAO,CAACa,YAAY,CAAC2D,gBAAgB,CAACF,GAAG,CAAC,EAAE;IACxD,MAAMA,GAAG;EACb,CAAC,MACI;IACD5C,IAAI,CAAC4C,GAAG,CAAC;EACb;AACJ,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM/G,eAAe,CAAC;EAClBqC,WAAW,CAACN,MAAM,EAAE;IAChB,IAAI,CAACA,MAAM,GAAGA,MAAM;EACxB;EACA;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;EACI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;EACI,MAAMmF,eAAe,CAACC,oBAAoB,EAAgB;IAAA,IAAdC,OAAO,uEAAG,CAAC,CAAC;IACpD,IAAIC,EAAE;IACN,IAAID,OAAO,CAACE,YAAY,KAAK,CAACD,EAAE,GAAGD,OAAO,CAACG,kBAAkB,MAAM,IAAI,IAAIF,EAAE,KAAK,KAAK,CAAC,GAAG,KAAK,CAAC,GAAGA,EAAE,CAACG,gBAAgB,CAAC,EAAE;MACtHJ,OAAO,CAACG,kBAAkB,CAACC,gBAAgB,CAACC,iBAAiB,GAAG,CAAC;IACrE,CAAC,MACI,IAAIL,OAAO,CAACE,YAAY,IACzBF,OAAO,CAACG,kBAAkB,KAAKrJ,SAAS,EAAE;MAC1CkJ,OAAO,CAACG,kBAAkB,GAAG;QACzBC,gBAAgB,EAAE;UACdC,iBAAiB,EAAE;QACvB;MACJ,CAAC;IACL;IACA,MAAMC,KAAK,GAAG,CAAC,CAAC,EAAEtH,SAAS,CAAC8D,OAAO,EAAEkD,OAAO,CAACO,gBAAgB,IAAI1G,6BAA6B,CAAC;IAC/F,MAAM2G,QAAQ,GAAG,EAAE;IACnB,IAAIC,QAAQ,GAAG,EAAE;IACjB,IAAI,CAACC,KAAK,CAACC,OAAO,CAACZ,oBAAoB,CAAC,EAAE;MACtC,WAAW,MAAMa,OAAO,IAAI,IAAI,CAACC,qBAAqB,CAACd,oBAAoB,CAAC,EAAE;QAC1EU,QAAQ,CAAC7B,IAAI,CAACgC,OAAO,CAAC;MAC1B;IACJ,CAAC,MACI;MACDH,QAAQ,GAAGV,oBAAoB;IACnC;IACA,KAAK,MAAMe,QAAQ,IAAIL,QAAQ,EAAE;MAC7B,MAAMM,IAAI,GAAG,MAAM7H,IAAI,CAACsH,QAAQ,CAACQ,KAAK,CAACF,QAAQ,CAAC;MAChD,IAAIC,IAAI,CAACE,WAAW,EAAE,EAAE;QACpB;MACJ;MACA,MAAMC,sBAAsB,GAAG;QAC3B,GAAGlB,OAAO,CAACG,kBAAkB;QAC7B,CAAC3G,SAAS,CAAC2H,gBAAgB,GAAG9G,oBAAoB,CAACC;MACvD,CAAC;MACD4G,sBAAsB,CAACE,WAAW,GAAGpB,OAAO,CAACqB,wBAAwB,GAC/DrB,OAAO,CAACqB,wBAAwB,CAACP,QAAQ,EAAEd,OAAO,CAAC,GACnDc,QAAQ,CAACQ,KAAK,CAACrI,IAAI,CAACsI,GAAG,CAAC,CAACC,IAAI,CAACvI,IAAI,CAACwI,KAAK,CAACF,GAAG,CAAC;MACnD,IAAIvB,OAAO,CAAC0B,MAAM,EAAE;QAChBR,sBAAsB,CAACE,WAAW,GAAGnI,IAAI,CAACwI,KAAK,CAACD,IAAI,CAAC,GAAGxB,OAAO,CAAC0B,MAAM,CAACJ,KAAK,CAACrI,IAAI,CAACsI,GAAG,CAAC,EAAEL,sBAAsB,CAACE,WAAW,CAAC;MAC/H;MACAZ,QAAQ,CAAC5B,IAAI,CAAC0B,KAAK,CAAC,MAAM,IAAI,CAAC3F,MAAM,CAACgH,MAAM,CAACb,QAAQ,EAAEI,sBAAsB,CAAC,CAAC,CAAC;IACpF;IACA,OAAOU,OAAO,CAACC,GAAG,CAACrB,QAAQ,CAAC;EAChC;EACA;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;EACI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;EACI,MAAMsB,iBAAiB,CAACC,aAAa,EAAgB;IAAA,IAAd/B,OAAO,uEAAG,CAAC,CAAC;IAC/C,MAAMM,KAAK,GAAG,CAAC,CAAC,EAAEtH,SAAS,CAAC8D,OAAO,EAAEkD,OAAO,CAACO,gBAAgB,IAAIzG,+BAA+B,CAAC;IACjG,MAAM0G,QAAQ,GAAG,EAAE;IACnB,IAAIwB,KAAK,GAAG,EAAE;IACd,IAAI,CAACtB,KAAK,CAACC,OAAO,CAACoB,aAAa,CAAC,EAAE;MAC/B,MAAME,cAAc,GAAG,MAAM,IAAI,CAACtH,MAAM,CAACuH,QAAQ,CAAC;QAC9CR,MAAM,EAAEK;MACZ,CAAC,CAAC;MACFC,KAAK,GAAGC,cAAc,CAAC,CAAC,CAAC;IAC7B,CAAC,MACI;MACDD,KAAK,GAAGD,aAAa,CAACI,GAAG,CAACC,OAAO,IAAI;QACjC,IAAI,OAAOA,OAAO,KAAK,QAAQ,EAAE;UAC7B,OAAO,IAAI,CAACzH,MAAM,CAAC0H,IAAI,CAACD,OAAO,CAAC;QACpC;QACA,OAAOA,OAAO;MAClB,CAAC,CAAC;IACN;IACA,MAAME,gBAAgB,GAAGtC,OAAO,CAACuC,WAAW,GACrC,IAAGvC,OAAO,CAACuC,WAAY,EAAC,GACzBnI,WAAW;IACjB,MAAMoI,KAAK,GAAG,IAAIC,MAAM,CAACH,gBAAgB,EAAE,GAAG,CAAC;IAC/C,KAAK,MAAMD,IAAI,IAAIL,KAAK,EAAE;MACtB,MAAMd,sBAAsB,GAAG;QAC3B,GAAGlB,OAAO,CAACG,kBAAkB;QAC7B,CAAC3G,SAAS,CAAC2H,gBAAgB,GAAG9G,oBAAoB,CAACE;MACvD,CAAC;MACD,IAAIyF,OAAO,CAAC0B,MAAM,IAAIR,sBAAsB,CAACE,WAAW,EAAE;QACtDF,sBAAsB,CAACE,WAAW,GAAGnI,IAAI,CAACuI,IAAI,CAACxB,OAAO,CAAC0B,MAAM,IAAI,EAAE,EAAER,sBAAsB,CAACE,WAAW,IAAI,EAAE,EAAEiB,IAAI,CAAC7G,IAAI,CAAC;MAC7H;MACA,IAAIwE,OAAO,CAACuC,WAAW,EAAE;QACrBrB,sBAAsB,CAACE,WAAW,GAAGiB,IAAI,CAAC7G,IAAI,CAACkH,OAAO,CAACF,KAAK,EAAE,EAAE,CAAC;MACrE;MACA,IAAIxC,OAAO,CAACE,YAAY,IACpB,CAAC,CAAC,EAAEhH,IAAI,CAACyJ,UAAU,EAAEzB,sBAAsB,CAACE,WAAW,IAAI,EAAE,CAAC,EAAE;QAChE;MACJ;MACAZ,QAAQ,CAAC5B,IAAI,CAAC0B,KAAK,CAAC,YAAY;QAC5B,MAAMc,WAAW,GAAGF,sBAAsB,CAACE,WAAW;QACtD,IAAIA,WAAW,IAAIA,WAAW,CAACwB,QAAQ,CAAC3J,IAAI,CAACsI,GAAG,CAAC,EAAE;UAC/C,MAAMrI,IAAI,CAACsH,QAAQ,CAACqC,KAAK,CAACzB,WAAW,EAAE;YAAE0B,SAAS,EAAE;UAAK,CAAC,CAAC;UAC3D,OAAOlB,OAAO,CAACmB,OAAO,CAAC,CACnBC,MAAM,CAACC,KAAK,CAAC,CAAC,CAAC,CAClB,CAAC;QACN;QACA,OAAOZ,IAAI,CAACa,QAAQ,CAAChC,sBAAsB,CAAC;MAChD,CAAC,CAAC,CAAC;IACP;IACA,OAAOU,OAAO,CAACC,GAAG,CAACrB,QAAQ,CAAC;EAChC;EACA;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;EACI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;EACI,MAAM2C,oBAAoB,CAACC,UAAU,EAAgB;IAAA,IAAdpD,OAAO,uEAAG,CAAC,CAAC;IAC/C,IAAIqD,SAAS,GAAGrD,OAAO,CAACsD,cAAc,IAAIrJ,qCAAqC;IAC/E,IAAIqG,KAAK,GAAG,CAAC,CAAC,EAAEtH,SAAS,CAAC8D,OAAO,EAAEkD,OAAO,CAACO,gBAAgB,IAAIxG,uCAAuC,CAAC;IACvG,MAAMwJ,YAAY,GAAGC,OAAO,CAACxD,OAAO,CAACuD,YAAY,CAAC;IAClD,MAAM/C,QAAQ,GAAG,EAAE;IACnB,MAAM6B,IAAI,GAAG,OAAOe,UAAU,KAAK,QAAQ,GACrC,IAAI,CAACzI,MAAM,CAAC0H,IAAI,CAACe,UAAU,CAAC,GAC5BA,UAAU;IAChB,MAAMK,QAAQ,GAAG,MAAMpB,IAAI,CAAChL,GAAG,EAAE;IACjC,MAAMqM,IAAI,GAAGC,QAAQ,CAACF,QAAQ,CAAC,CAAC,CAAC,CAACG,QAAQ,CAACF,IAAI,CAACG,QAAQ,EAAE,CAAC;IAC3D;IACA,IAAIH,IAAI,GAAG1J,sCAAsC,EAAE;MAC/CsG,KAAK,GAAG,CAAC,CAAC,EAAEtH,SAAS,CAAC8D,OAAO,EAAE,CAAC,CAAC;MACjCuG,SAAS,GAAGK,IAAI;IACpB;IACA,IAAII,KAAK,GAAG,CAAC;IACb,MAAMhD,QAAQ,GAAGd,OAAO,CAACoB,WAAW,IAAInI,IAAI,CAAC8K,QAAQ,CAAC1B,IAAI,CAAC7G,IAAI,CAAC;IAChE,MAAMwI,WAAW,GAAG,MAAM9K,IAAI,CAACsH,QAAQ,CAACyD,IAAI,CAACnD,QAAQ,EAAE,GAAG,CAAC;IAC3D,OAAOgD,KAAK,GAAGJ,IAAI,EAAE;MACjB,MAAMQ,UAAU,GAAGJ,KAAK;MACxB,IAAIK,QAAQ,GAAGL,KAAK,GAAGT,SAAS,GAAG,CAAC;MACpCc,QAAQ,GAAGA,QAAQ,GAAGT,IAAI,GAAGA,IAAI,GAAGS,QAAQ;MAC5C3D,QAAQ,CAAC5B,IAAI,CAAC0B,KAAK,CAAC,YAAY;QAC5B,MAAM8D,IAAI,GAAG,MAAM/B,IAAI,CAACa,QAAQ,CAAC;UAC7BY,KAAK,EAAEI,UAAU;UACjBG,GAAG,EAAEF,QAAQ;UACb,CAAC3K,SAAS,CAAC2H,gBAAgB,GAAG9G,oBAAoB,CAACI;QACvD,CAAC,CAAC;QACF,MAAM7C,MAAM,GAAG,MAAMoM,WAAW,CAACM,KAAK,CAACF,IAAI,CAAC,CAAC,CAAC,EAAE,CAAC,EAAEA,IAAI,CAAC,CAAC,CAAC,CAACG,MAAM,EAAEL,UAAU,CAAC;QAC9E,IAAIX,YAAY,EACZ;QACJ,OAAO3L,MAAM,CAAC4M,MAAM;MACxB,CAAC,CAAC,CAAC;MACHV,KAAK,IAAIT,SAAS;IACtB;IACA,IAAIoB,MAAM;IACV,IAAI;MACAA,MAAM,GAAG,MAAM7C,OAAO,CAACC,GAAG,CAACrB,QAAQ,CAAC;IACxC,CAAC,SACO;MACJ,MAAMwD,WAAW,CAACU,KAAK,EAAE;IAC7B;IACA,IAAI1E,OAAO,CAACnC,UAAU,KAAK,QAAQ,IAAI4F,QAAQ,CAAC,CAAC,CAAC,CAACG,QAAQ,CAACe,MAAM,EAAE;MAChE,MAAMC,gBAAgB,GAAG,MAAMzL,WAAW,CAAC0L,MAAM,CAACC,QAAQ,CAAChE,QAAQ,CAAC;MACpE,IAAI,CAAC8D,gBAAgB,CAACG,QAAQ,CAACtB,QAAQ,CAAC,CAAC,CAAC,CAACG,QAAQ,CAACe,MAAM,CAAC,EAAE;QACzD,MAAMK,aAAa,GAAG,IAAIlM,SAAS,CAACmM,YAAY,CAACnM,SAAS,CAACoM,qBAAqB,CAACC,iBAAiB,CAAC;QACnGH,aAAa,CAACI,IAAI,GAAG,2BAA2B;QAChD,MAAMJ,aAAa;MACvB;IACJ;IACA,IAAIzB,YAAY,EACZ;IACJ,OAAO,CAACP,MAAM,CAACqC,MAAM,CAACZ,MAAM,EAAEf,IAAI,CAAC,CAAC;EACxC;EACA;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;EACI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;EACI,MAAM4B,kBAAkB,CAACxE,QAAQ,EAAuD;IAAA,IAArDd,OAAO,uEAAG,CAAC,CAAC;IAAA,IAAEuF,SAAS,uEAAG7K,yBAAyB;IAClF,MAAM2I,SAAS,GAAGrD,OAAO,CAACsD,cAAc,IAAIpJ,mCAAmC;IAC/E,MAAMoG,KAAK,GAAG,CAAC,CAAC,EAAEtH,SAAS,CAAC8D,OAAO,EAAEkD,OAAO,CAACO,gBAAgB,IAAIpG,qCAAqC,CAAC;IACvG,MAAMqL,YAAY,GAAGxF,OAAO,CAACwF,YAAY,IACrCxF,OAAO,CAACO,gBAAgB,IACxBpG,qCAAqC;IACzC,MAAMS,QAAQ,GAAGoF,OAAO,CAACyF,UAAU,IAAIxM,IAAI,CAAC8K,QAAQ,CAACjD,QAAQ,CAAC;IAC9D,MAAM4E,SAAS,GAAGH,SAAS,CAAC,IAAI,CAAC5K,MAAM,EAAEC,QAAQ,EAAEoF,OAAO,CAACnF,QAAQ,EAAEmF,OAAO,CAAClF,QAAQ,CAAC;IACtF,IAAI6C,UAAU,GAAG,CAAC;IAClB,IAAI6C,QAAQ,GAAG,EAAE;IACjB,IAAI;MACA,IAAIR,OAAO,CAACnF,QAAQ,KAAK/D,SAAS,EAAE;QAChC,MAAM4O,SAAS,CAAC/I,cAAc,CAACqD,OAAO,CAACpD,OAAO,CAAC;MACnD;MACA,MAAM+I,qBAAqB,GAAGD,SAAS,CAAC5K,QAAQ,CAAC4I,IAAI,GAAGL,SAAS;MACjE,MAAMuC,UAAU,GAAG,CAAC,CAAC,EAAE1M,IAAI,CAAC2M,gBAAgB,EAAE/E,QAAQ,EAAE;QACpDgF,aAAa,EAAEzC,SAAS;QACxBS,KAAK,EAAE6B;MACX,CAAC,CAAC;MACF;MACA;MACA,WAAW,MAAMI,QAAQ,IAAIH,UAAU,EAAE;QACrC,IAAIpF,QAAQ,CAAC+D,MAAM,IAAIiB,YAAY,EAAE;UACjC,MAAM5D,OAAO,CAACC,GAAG,CAACrB,QAAQ,CAAC;UAC3BA,QAAQ,GAAG,EAAE;QACjB;QACAA,QAAQ,CAAC5B,IAAI,CAAC0B,KAAK,CAAC,MAAMoF,SAAS,CAAChI,UAAU,CAACC,UAAU,EAAE,EAAEoI,QAAQ,EAAE/F,OAAO,CAACnC,UAAU,CAAC,CAAC,CAAC;MAChG;MACA,MAAM+D,OAAO,CAACC,GAAG,CAACrB,QAAQ,CAAC;MAC3B,OAAO,MAAMkF,SAAS,CAACtH,cAAc,EAAE;IAC3C,CAAC,CACD,OAAOX,CAAC,EAAE;MACN,IAAI,CAACuC,OAAO,CAACgG,gBAAgB,KAAKlP,SAAS,IAAIkJ,OAAO,CAACgG,gBAAgB,KACnEN,SAAS,CAAC7K,QAAQ,EAAE;QACpB,IAAI;UACA,MAAM6K,SAAS,CAAC1G,WAAW,EAAE;UAC7B;QACJ,CAAC,CACD,OAAOvB,CAAC,EAAE;UACN,MAAM,IAAI5E,oBAAoB,CAAC4E,CAAC,CAACvC,OAAO,EAAEwK,SAAS,CAAC7K,QAAQ,EAAE6K,SAAS,CAAC5K,QAAQ,CAAC;QACrF;MACJ;MACA,MAAM,IAAIjC,oBAAoB,CAAC4E,CAAC,CAACvC,OAAO,EAAEwK,SAAS,CAAC7K,QAAQ,EAAE6K,SAAS,CAAC5K,QAAQ,CAAC;IACrF;EACJ;EACA,OAAO+F,qBAAqB,CAACoF,SAAS,EAAE;IACpC,MAAMC,sBAAsB,GAAG,MAAMhN,IAAI,CAACsH,QAAQ,CAAC2F,OAAO,CAACF,SAAS,EAAE;MAClEG,aAAa,EAAE;IACnB,CAAC,CAAC;IACF,KAAK,MAAMC,kBAAkB,IAAIH,sBAAsB,EAAE;MACrD,MAAMI,QAAQ,GAAGrN,IAAI,CAACuI,IAAI,CAACyE,SAAS,EAAEI,kBAAkB,CAAC7K,IAAI,CAAC;MAC9D6K,kBAAkB,CAACpF,WAAW,EAAE,GAC1B,OAAO,IAAI,CAACJ,qBAAqB,CAACyF,QAAQ,CAAC,GAC3C,MAAMA,QAAQ;IACxB;EACJ;AACJ;AACA3N,OAAO,CAACC,eAAe,GAAGA,eAAe"},"metadata":{},"sourceType":"script","externalDependencies":[]}